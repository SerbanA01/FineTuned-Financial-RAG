{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the same model used for indexing\n",
    "# Make sure this matches what generated your .npy files\n",
    "embedding_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "try:\n",
    "    query_model = SentenceTransformer(embedding_model_name)\n",
    "    print(f\"Embedding model '{embedding_model_name}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embedding model: {e}\")\n",
    "    # Handle error: model might not be downloaded, or path is wrong\n",
    "    query_model = None\n",
    "\n",
    "\n",
    "def get_query_embedding(query_text: str):\n",
    "    if not query_model:\n",
    "        raise ValueError(\"Embedding model not loaded.\")\n",
    "    # The model expects a list of texts, even if it's just one\n",
    "    #q_emb = enc.encode(question, normalize_embeddings=True).tolist()\n",
    "    q_emb = query_model.encode(query_text, normalize_embeddings=True).tolist()\n",
    "    return q_emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17a8a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.26.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install groq\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70461828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Now it should work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5479dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Tuple, Set, Dict, Any, Optional\n",
    "\n",
    "# --- Mappings (as you defined them) ---\n",
    "COMPANY_TO_TICKER_HINTS = {\n",
    "    \"apple\": \"AAPL\", \"microsoft\": \"MSFT\", \"google\": \"GOOGL\", \"alphabet\": \"GOOGL\",\n",
    "    \"amazon\": \"AMZN\", \"nvidia\": \"NVDA\", \"meta\": \"META\", \"tesla\": \"TSLA\",\n",
    "    \"meta platforms\": \"META\", \"facebook\": \"META\",  # Facebook is now Meta\n",
    "    \"berkshire hathaway\": \"BRK.B\", \"bank of america\": \"BAC\", \"boa\": \"BAC\",\n",
    "    \"boeing\": \"BA\", \"coca cola\": \"KO\", \"coca-cola\": \"KO\", \"cola\": \"KO\", \"coke\": \"KO\",\n",
    "    \"johnson & johnson\": \"JNJ\", \"j&j\": \"JNJ\", \"johnson and johnson\": \"JNJ\",\n",
    "    \"procter & gamble\": \"PG\", \"p&g\": \"PG\", \"procter and gamble\": \"PG\",\n",
    "    \"walmart\": \"WMT\", \"wal-mart\": \"WMT\", \"wally world\": \"WMT\",\n",
    "    \"united parcel service\": \"UPS\", \"ups\": \"UPS\", \"parcel service\": \"UPS\",\n",
    "    \"general electric\": \"GE\", \"ge\": \"GE\",\n",
    "    \"ibm\": \"IBM\", \"international business machines\": \"IBM\",\n",
    "    \"american express\": \"AXP\", \"amex\": \"AXP\",\n",
    "    \"home depot\": \"HD\", \"hd\": \"HD\",\n",
    "    \"mcdonald's\": \"MCD\", \"mcdonalds\": \"MCD\", \"mcd\": \"MCD\", \"mickey d's\": \"MCD\",\n",
    "    \"jpmorgan\": \"JPM\", \"jp morgan\": \"JPM\", \"jpm\": \"JPM\",\n",
    "    \"wells fargo\": \"WFC\", \"citigroup\": \"C\", \"citi\": \"C\",\n",
    "    \"goldman sachs\": \"GS\", \"morgan stanley\": \"MS\",\n",
    "    \"charles schwab\": \"SCHW\", \"schwab\": \"SCHW\",\n",
    "    \"blackrock\": \"BLK\", \"black rock\": \"BLK\",\n",
    "    \"s&p global\": \"SPGI\", \"sandp global\": \"SPGI\",\n",
    "    \"moody's\": \"MCO\", \"moodys\": \"MCO\",\n",
    "    \"intercontinental exchange\": \"ICE\",\n",
    "    \"walt disney\": \"DIS\", \"disney\": \"DIS\", \"disney co\": \"DIS\",\n",
    "    \"comcast\": \"CMCSA\", \"netflix\": \"NFLX\",\n",
    "    \"verizon\": \"VZ\", \"at&t\": \"T\", \"att\": \"T\",\n",
    "    \"t-mobile\": \"TMUS\", \"tmobile\": \"TMUS\",\n",
    "    \"charter\": \"CHTR\", \"fox\": \"FOXA\", \"news corp\": \"NWSA\",\n",
    "    \"honeywell\": \"HON\", \"union pacific\": \"UNP\",\n",
    "    \"3m\": \"MMM\", \"caterpillar\": \"CAT\", \"cat\": \"CAT\",\n",
    "    \"lockheed martin\": \"LMT\", \"raytheon\": \"RTX\",\n",
    "    \"northrop grumman\": \"NOC\", \"northrop\": \"NOC\",\n",
    "    \"illinois tool works\": \"ITW\", \"deere\": \"DE\", \"john deere\": \"DE\",\n",
    "    \"fedex\": \"FDX\", \"fed ex\": \"FDX\",\n",
    "    \"pepsico\": \"PEP\", \"pepsi\": \"PEP\",\n",
    "    \"costco\": \"COST\", \"mondelez\": \"MDLZ\", \"colgate-palmolive\": \"CL\", \"colgate\": \"CL\",\n",
    "    \"kimberly-clark\": \"KMB\", \"general mills\": \"GIS\", \"kraft heinz\": \"KHC\",\n",
    "    \"altria\": \"MO\", \"philip morris\": \"PM\", \"pm\": \"PM\",\n",
    "    \"exxon mobil\": \"XOM\", \"exxon\": \"XOM\", \"mobil\": \"XOM\",\n",
    "    \"chevron\": \"CVX\", \"conocophillips\": \"COP\", \"conoco\": \"COP\",\n",
    "    \"schlumberger\": \"SLB\", \"halliburton\": \"HAL\",\n",
    "    \"eog resources\": \"EOG\", \"marathon petroleum\": \"MPC\", \"marathon\": \"MPC\",\n",
    "    \"phillips 66\": \"PSX\", \"valero\": \"VLO\",\n",
    "    \"kinder morgan\": \"KMI\", \"williams companies\": \"WMB\",\n",
    "    \"devon energy\": \"DVN\",\n",
    "    \"nextera energy\": \"NEE\", \"duke energy\": \"DUK\",\n",
    "    \"southern company\": \"SO\", \"dominion energy\": \"D\",\n",
    "    \"american electric power\": \"AEP\", \"exelon\": \"EXC\",\n",
    "    \"sempra\": \"SRE\", \"xcel energy\": \"XEL\",\n",
    "    \"public service enterprise group\": \"PEG\",\n",
    "    \"consolidated edison\": \"ED\", \"entergy\": \"ETR\", \"firstenergy\": \"FE\",\n",
    "    \"american tower\": \"AMT\", \"prologis\": \"PLD\",\n",
    "    \"crown castle\": \"CCI\", \"equinix\": \"EQIX\", \"public storage\": \"PSA\",\n",
    "    \"simon property\": \"SPG\", \"digital realty\": \"DLR\",\n",
    "    \"welltower\": \"WELL\", \"realty income\": \"O\",\n",
    "    \"alexandria real estate\": \"ARE\", \"avalonbay\": \"AVB\",\n",
    "    \"equity residential\": \"EQR\",\n",
    "    \"linde\": \"LIN\", \"air products\": \"APD\",\n",
    "    \"sherwin-williams\": \"SHW\", \"sherwin williams\": \"SHW\",\n",
    "    \"dow\": \"DOW\", \"dupont\": \"DD\", \"newmont\": \"NEM\",\n",
    "    \"freeport-mcmoran\": \"FCX\", \"freeport\": \"FCX\",\n",
    "    \"international paper\": \"IP\", \"ball\": \"BALL\", \"albemarle\": \"ALB\",\n",
    "    \"vision 2020\": \"V2020\", \"vision2020\": \"V2020\", \"v2020\": \"V2020\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "TICKER_TO_COMPANY_HINTS = {}\n",
    "for name, ticker in COMPANY_TO_TICKER_HINTS.items():\n",
    "    if ticker not in TICKER_TO_COMPANY_HINTS:\n",
    "        TICKER_TO_COMPANY_HINTS[ticker] = name.title()\n",
    "# Crucial check: Ensure BRK.A and V2020 are in TICKER_TO_COMPANY_HINTS\n",
    "if \"BRK.A\" not in TICKER_TO_COMPANY_HINTS and \"berkshire hathaway a\" in COMPANY_TO_TICKER_HINTS :\n",
    "     TICKER_TO_COMPANY_HINTS[\"BRK.A\"] = COMPANY_TO_TICKER_HINTS[\"berkshire hathaway a\"].title()\n",
    "if \"V2020\" not in TICKER_TO_COMPANY_HINTS and \"vision 2020\" in COMPANY_TO_TICKER_HINTS:\n",
    "     TICKER_TO_COMPANY_HINTS[\"V2020\"] = COMPANY_TO_TICKER_HINTS[\"vision 2020\"].title()\n",
    "\n",
    "\n",
    "TICKER_REGEX = re.compile(r'\\b([A-Z]{1,5}(\\.[A-Z])?)\\b')\n",
    "YEAR_REGEX = re.compile(r'\\b(19[7-9]\\d|20\\d{2})\\b')\n",
    "QUARTER_REGEX = re.compile(\n",
    "    r'\\b(?:Q([1-4])|'\n",
    "    r'(?:Quarter\\s*([1-4]))|'\n",
    "    r'(1st|2nd|3rd|4th)\\s*Quarter|'\n",
    "    r'(first|second|third|fourth)\\s*Quarter)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "QUARTER_WORD_TO_NUM = {\n",
    "    \"1st\": 1, \"first\": 1, \"2nd\": 2, \"second\": 2,\n",
    "    \"3rd\": 3, \"third\": 3, \"4th\": 4, \"fourth\": 4,\n",
    "}\n",
    "\n",
    "class EntityType:\n",
    "    TICKER = \"ticker\"; COMPANY = \"company\"; YEAR = \"year\"; QUARTER = \"quarter\"\n",
    "\n",
    "ENTITY_PRIORITIES = {\n",
    "    EntityType.TICKER: 0, EntityType.YEAR: 1,\n",
    "    EntityType.QUARTER: 2, EntityType.COMPANY: 3\n",
    "}\n",
    "\n",
    "class QueryFocus:\n",
    "    def __init__(self, ticker: str, year: Optional[int] = None, quarter: Optional[int] = None): # Removed original_segment for brevity\n",
    "        self.ticker = ticker; self.year = year; self.quarter = quarter\n",
    "    def __repr__(self):\n",
    "        return f\"QueryFocus(ticker='{self.ticker}', year={self.year}, quarter={self.quarter})\"\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, QueryFocus) and self.ticker == other.ticker and self.year == other.year and self.quarter == other.quarter\n",
    "    def __hash__(self):\n",
    "        return hash((self.ticker, self.year, self.quarter))\n",
    "\n",
    "def _extract_entities_from_segment_text(segment_text: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Extracts entities from a given text segment. Indices are relative to segment_text.\"\"\"\n",
    "    potential_entities: List[Dict[str, Any]] = []\n",
    "    # Tickers\n",
    "    for match in TICKER_REGEX.finditer(segment_text):\n",
    "        ticker_candidate = match.group(1)\n",
    "        if ticker_candidate in TICKER_TO_COMPANY_HINTS: # Check if it's a known ticker\n",
    "            potential_entities.append({\n",
    "                \"text\": ticker_candidate, \"value\": ticker_candidate, \"type\": EntityType.TICKER,\n",
    "                \"start\": match.start(1), \"end\": match.end(1), \"priority\": ENTITY_PRIORITIES[EntityType.TICKER]\n",
    "            })\n",
    "    # Company names\n",
    "    for cn_key in sorted(COMPANY_TO_TICKER_HINTS.keys(), key=len, reverse=True):\n",
    "        ticker = COMPANY_TO_TICKER_HINTS[cn_key]\n",
    "        pattern = r'\\b' + re.escape(cn_key) + r'\\b'\n",
    "        for cmatch in re.finditer(pattern, segment_text, re.IGNORECASE):\n",
    "            potential_entities.append({\n",
    "                \"text\": cmatch.group(0), \"value\": ticker, \"type\": EntityType.COMPANY,\n",
    "                \"start\": cmatch.start(0), \"end\": cmatch.end(0), \"priority\": ENTITY_PRIORITIES[EntityType.COMPANY]\n",
    "            })\n",
    "    # Years\n",
    "    for ymatch in YEAR_REGEX.finditer(segment_text):\n",
    "        year_str = ymatch.group(1)\n",
    "        potential_entities.append({\n",
    "            \"text\": year_str, \"value\": int(year_str), \"type\": EntityType.YEAR,\n",
    "            \"start\": ymatch.start(1), \"end\": ymatch.end(1), \"priority\": ENTITY_PRIORITIES[EntityType.YEAR]\n",
    "        })\n",
    "    # Quarters\n",
    "    for qmatch in QUARTER_REGEX.finditer(segment_text):\n",
    "        q_val_str = qmatch.group(1) or qmatch.group(2) or qmatch.group(3) or qmatch.group(4)\n",
    "        q_num = None\n",
    "        if q_val_str: q_num = int(q_val_str) if q_val_str.isdigit() else QUARTER_WORD_TO_NUM.get(q_val_str.lower())\n",
    "        if q_num:\n",
    "            potential_entities.append({\n",
    "                \"text\": qmatch.group(0), \"value\": q_num, \"type\": EntityType.QUARTER,\n",
    "                \"start\": qmatch.start(0), \"end\": qmatch.end(0), \"priority\": ENTITY_PRIORITIES[EntityType.QUARTER]\n",
    "            })\n",
    "    return potential_entities\n",
    "\n",
    "# Sentence delimiters\n",
    "SENTENCE_DELIMITERS_REGEX = re.compile(r'[.?!]')\n",
    "CLAUSE_DELIMITERS_REGEX = re.compile(r'\\s+(?:and|or|but)\\s+|,', re.IGNORECASE)\n",
    "\n",
    "def extract_structured_metadata(query: str) -> Tuple[List[QueryFocus], str]:\n",
    "    all_query_focuses_set: Set[QueryFocus] = set()\n",
    "    \n",
    "    # --- Global Entity Extraction (for final query cleaning and global context) ---\n",
    "    glob_potential_entities = _extract_entities_from_segment_text(query)\n",
    "    glob_potential_entities.sort(key=lambda x: (x[\"start\"], x[\"priority\"], -(x[\"end\"] - x[\"start\"])))\n",
    "    \n",
    "    all_extracted_entities_globally: List[Dict[str, Any]] = []\n",
    "    _last_covered_idx = -1\n",
    "    for entity in glob_potential_entities:\n",
    "        if entity[\"start\"] >= _last_covered_idx:\n",
    "            all_extracted_entities_globally.append(entity)\n",
    "            _last_covered_idx = entity[\"end\"]\n",
    "    \n",
    "    # --- Determine \"Global Default\" Context (only if unique across whole query) ---\n",
    "    global_years_map = {}\n",
    "    global_quarters_map = {}\n",
    "    for entity in all_extracted_entities_globally:\n",
    "        if entity[\"type\"] == EntityType.YEAR: global_years_map[entity[\"value\"]] = global_years_map.get(entity[\"value\"], 0) + 1\n",
    "        elif entity[\"type\"] == EntityType.QUARTER: global_quarters_map[entity[\"value\"]] = global_quarters_map.get(entity[\"value\"], 0) + 1\n",
    "            \n",
    "    default_year = list(global_years_map.keys())[0] if len(global_years_map) == 1 else None\n",
    "    default_quarter = list(global_quarters_map.keys())[0] if len(global_quarters_map) == 1 else None\n",
    "    \n",
    "    # --- Hierarchical Segmentation ---\n",
    "    query_segments = []\n",
    "    initial_sentences = SENTENCE_DELIMITERS_REGEX.split(query)\n",
    "    for sentence_text in initial_sentences:\n",
    "        if not sentence_text.strip(): continue\n",
    "        clauses_text = []\n",
    "        last_clause_split_end = 0\n",
    "        for match in CLAUSE_DELIMITERS_REGEX.finditer(sentence_text):\n",
    "            clauses_text.append(sentence_text[last_clause_split_end:match.start()].strip())\n",
    "            last_clause_split_end = match.end()\n",
    "        clauses_text.append(sentence_text[last_clause_split_end:].strip())\n",
    "        query_segments.extend([c for c in clauses_text if c])\n",
    "    \n",
    "    if not query_segments and query.strip(): # If no delimiters found, whole query is one segment\n",
    "        query_segments.append(query.strip())\n",
    "\n",
    "    # --- Process Each Segment for Pairing ---\n",
    "    for segment_text in query_segments:\n",
    "        if not segment_text.strip(): continue\n",
    "\n",
    "        segment_potential_entities = _extract_entities_from_segment_text(segment_text)\n",
    "        segment_potential_entities.sort(key=lambda x: (x[\"start\"], x[\"priority\"], -(x[\"end\"] - x[\"start\"])))\n",
    "\n",
    "        segment_selected_entities: List[Dict[str, Any]] = []\n",
    "        _last_seg_idx = -1\n",
    "        for entity in segment_potential_entities:\n",
    "            if entity[\"start\"] >= _last_seg_idx:\n",
    "                segment_selected_entities.append(entity)\n",
    "                _last_seg_idx = entity[\"end\"]\n",
    "        \n",
    "        seg_stocks = [e for e in segment_selected_entities if e[\"type\"] in (EntityType.TICKER, EntityType.COMPANY)]\n",
    "        seg_years = sorted([e for e in segment_selected_entities if e[\"type\"] == EntityType.YEAR], key=lambda y: y[\"start\"])\n",
    "        seg_quarters = sorted([e for e in segment_selected_entities if e[\"type\"] == EntityType.QUARTER], key=lambda q: q[\"start\"])\n",
    "\n",
    "        if not seg_stocks: continue\n",
    "\n",
    "        for stock_entity in seg_stocks:\n",
    "            current_ticker = stock_entity[\"value\"]\n",
    "            assigned_year: Optional[int] = None\n",
    "            assigned_quarter: Optional[int] = None\n",
    "\n",
    "            if seg_years:\n",
    "                assigned_year = min(seg_years, key=lambda y: abs(y[\"start\"] - stock_entity[\"start\"]))[\"value\"]\n",
    "            if seg_quarters:\n",
    "                assigned_quarter = min(seg_quarters, key=lambda q: abs(q[\"start\"] - stock_entity[\"start\"]))[\"value\"]\n",
    "            \n",
    "            # Apply defaults with more conservative logic\n",
    "            if assigned_year is None:\n",
    "                # Only apply default_year if segment has NO quarter, or if it has a quarter but default_year is \"strong\"\n",
    "                if assigned_quarter is None and default_year is not None: # No time info in segment\n",
    "                    assigned_year = default_year\n",
    "                elif assigned_quarter is not None and default_year is not None: # Segment has Q, missing Y\n",
    "                     assigned_year = default_year # This allows Tesla 2023 Q1 if default_year=2023\n",
    "                     # To prevent Tesla 2023 Q1: default_year should only apply if segment has NO quarter.\n",
    "                     # Let's refine:\n",
    "                     # if assigned_quarter is None and default_year is not None:\n",
    "                     #     assigned_year = default_year\n",
    "\n",
    "            # More conservative default year:\n",
    "            if assigned_year is None and assigned_quarter is None and default_year is not None:\n",
    "                 assigned_year = default_year\n",
    "            # If segment has a quarter but no year, only then try default year.\n",
    "            elif assigned_year is None and assigned_quarter is not None and default_year is not None:\n",
    "                 assigned_year = default_year\n",
    "\n",
    "\n",
    "            if assigned_quarter is None and default_quarter is not None:\n",
    "                # Apply default quarter if there's some year context or it's the only thing\n",
    "                if assigned_year is not None: # Year context exists for this stock\n",
    "                    assigned_quarter = default_quarter\n",
    "                elif default_year is None : # No year context at all, but a lone default quarter\n",
    "                    assigned_quarter = default_quarter\n",
    "\n",
    "\n",
    "            all_query_focuses_set.add(QueryFocus(ticker=current_ticker, year=assigned_year, quarter=assigned_quarter))\n",
    "\n",
    "    # --- Final Query Modification ---\n",
    "    modified_query_parts = []\n",
    "    current_pos = 0\n",
    "    for entity in all_extracted_entities_globally: # Use globally resolved entities\n",
    "        if entity[\"start\"] > current_pos:\n",
    "            modified_query_parts.append(query[current_pos:entity[\"start\"]])\n",
    "        \n",
    "        end_skip = entity[\"end\"]\n",
    "        if entity[\"type\"] in (EntityType.TICKER, EntityType.COMPANY) and not entity[\"text\"].lower().endswith(\"'s\"):\n",
    "            if entity[\"end\"] + 1 < len(query) and query[entity[\"end\"]] == \"'\" and query[entity[\"end\"]+1].lower() == \"s\":\n",
    "                end_skip = entity[\"end\"] + 2\n",
    "        current_pos = end_skip\n",
    "\n",
    "    if current_pos < len(query): modified_query_parts.append(query[current_pos:])\n",
    "    modified_query = ' '.join(\"\".join(modified_query_parts).split()).strip()\n",
    "\n",
    "    return sorted(list(all_query_focuses_set), key=lambda qf: (\n",
    "        qf.ticker, qf.year or -1, qf.quarter or -1\n",
    "    )), modified_query\n",
    "\n",
    "#groq intilizing\n",
    "import groq\n",
    "import json\n",
    "import os\n",
    "groq.api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "# Ensure the environment variable is set\n",
    "if not groq.api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY environment variable is not set.\")\n",
    "# --- Functionality Test ---\n",
    "try:\n",
    "    groq_client = groq.Client()\n",
    "    print(\"Groq client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Groq client: {e}\")\n",
    "    # Handle error: client might not be initialized properly\n",
    "    groq_client = None\n",
    "\n",
    "\n",
    "LLM_MODEL_NAME = \"llama3-8b-8192\" # Or \"mixtral-8x7b-32768\", \"llama3-70b-8192\" etc.\n",
    "\n",
    "def format_rule_based_output_for_prompt(focuses: List[QueryFocus]) -> str:\n",
    "    if not focuses:\n",
    "        return \"Rule-based extraction found no specific company/ticker focuses.\"\n",
    "    \n",
    "    formatted_str = \"Rule-Based Extraction Results:\\n\"\n",
    "    for i, focus in enumerate(focuses):\n",
    "        year_str = str(focus.year) if focus.year is not None else \"Not specified\"\n",
    "        quarter_str = \"Q\" + str(focus.quarter) if focus.quarter is not None else \"Not specified\"\n",
    "        formatted_str += f\"- Focus {i+1}: Ticker={focus.ticker}, Year={year_str}, Quarter={quarter_str}\\n\"\n",
    "    return formatted_str.strip()\n",
    "\n",
    "def refine_with_llm(original_query: str, rule_based_focuses: List[QueryFocus]) -> List[QueryFocus]:\n",
    "    if not groq_client:\n",
    "        print(\"Groq client not initialized. Returning rule-based results.\")\n",
    "        return rule_based_focuses\n",
    "\n",
    "    rule_based_output_str = format_rule_based_output_for_prompt(rule_based_focuses)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an expert financial data analyst assistant. Your task is to review a user's query and a preliminary rule-based extraction of company tickers, years, and quarters.\n",
    "Your goal is to produce a corrected list of (Ticker, Year, Quarter) focuses that accurately reflect all distinct requests for financial data implied by the user's query.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the \"Original Query\" to understand the user's full intent, paying close attention to context.\n",
    "2. Review the \"Rule-Based Extraction Results\". This is an initial attempt and may contain errors, omissions, or irrelevant focuses.\n",
    "\n",
    "IMPORTANT - EVALUATING AND REFINING FOCUSES:\n",
    "- Your primary role is to:\n",
    "    a) CORRECT errors in the pairing of (Ticker, Year, Quarter) within each valid focus.\n",
    "    b) ADD any focuses for financial data requests COMPLETELY MISSED by the rule-based system.\n",
    "    c) REMOVE focuses from the rule-based results if they correspond to a company/ticker mention that, in the context of the *entire query*, is CLEARLY NOT a request for that company's financial data. For example:\n",
    "        - If \"Apple\" is mentioned in the context of eating fruit, a rule-based focus for \"AAPL\" should be removed.\n",
    "        - If a company is mentioned as a source of data (e.g., \"Data provided by FactSet\"), a focus for FactSet's own financials should be removed unless explicitly requested.\n",
    "        - If a company name is part of a general phrase or a different entity (e.g., \"Amazon River tour\"), a focus for \"AMZN\" should be removed.\n",
    "- However, if a company/ticker is mentioned and the context suggests a potential interest in its financial data or performance, even if part of a complex sentence, you should AIM TO PRESERVE and CORRECT its focus rather than discarding it. For example, if the query is \"Info on Apple in 2023 Q1 and also Google news\", and the rule-based system provides focuses for both Apple and Google, your output MUST include focuses for both, refining their year/quarter as needed.\n",
    "\n",
    "4. If a year or quarter is not specified or implied for a particular company's valid financial data request, use `null` for that field.\n",
    "5. Ensure years and quarters are correctly associated with their respective tickers for each valid request.\n",
    "6. If the rule-based extraction is already perfect for all valid financial data requests, your output should be identical to it.\n",
    "\n",
    "Output Format:\n",
    "Return ONLY a valid JSON list of objects. Each object MUST have: \"ticker\" (string), \"year\" (integer or null), \"quarter\" (integer 1-4 or null).\n",
    "Do NOT include any other text.\n",
    "Example 1:\n",
    "Query: \"Apple Q1 2022 and Google Q2 2023\"\n",
    "Expected JSON:\n",
    "[\n",
    "  {\"ticker\": \"AAPL\", \"year\": 2022, \"quarter\": 1},\n",
    "  {\"ticker\": \"GOOGL\", \"year\": 2023, \"quarter\": 2}\n",
    "]\n",
    "\n",
    "Example 2:\n",
    "Query: \"Microsoft and Nvidia performance in 2023 Q4\"\n",
    "Expected JSON:\n",
    "[\n",
    "  {\"ticker\": \"MSFT\", \"year\": 2023, \"quarter\": 4},\n",
    "  {\"ticker\": \"NVDA\", \"year\": 2023, \"quarter\": 4}\n",
    "]\n",
    "\n",
    "Example 3:\n",
    "Query: \"Tesla sales for Q1 this year. Also Amazon results.\"\n",
    "(Assume \"this year\" means current year, e.g., 2024, for the LLM to potentially infer or for you to pre-process)\n",
    "Expected JSON (if LLM infers current year for Tesla, or you add it):\n",
    "[\n",
    "  {\"ticker\": \"TSLA\", \"year\": 2024, \"quarter\": 1},\n",
    "  {\"ticker\": \"AMZN\", \"year\": null, \"quarter\": null}\n",
    "]\n",
    "(If LLM doesn't infer year for Tesla)\n",
    "[\n",
    "  {\"ticker\": \"TSLA\", \"year\": null, \"quarter\": 1},\n",
    "  {\"ticker\": \"AMZN\", \"year\": null, \"quarter\": null}\n",
    "]\n",
    "Example (Contextual Discard):\n",
    "Query: \"I like to eat an apple a day. What about Microsoft's Q1 earnings?\"\n",
    "Rule-Based: [{\"ticker\": \"AAPL\", \"year\": null, \"quarter\": null}, {\"ticker\": \"MSFT\", \"year\": null, \"quarter\": 1}]\n",
    "Expected JSON:\n",
    "[\n",
    "  {\"ticker\": \"MSFT\", \"year\": null, \"quarter\": 1}\n",
    "]\n",
    "// Note: AAPL focus removed due to fruit context.\n",
    "\n",
    "Example (Preserving Multiple Valid Requests):\n",
    "Query: \"Company Vision 2020 report for 2020 Q1 and Apple news.\"\n",
    "Rule-Based: [{\"ticker\": \"V2020\", \"year\": 2020, \"quarter\": 1}, {\"ticker\": \"AAPL\", \"year\": 2020, \"quarter\": 1}]\n",
    "Expected JSON (LLM should preserve both, possibly refining AAPL's year/quarter if context suggests different):\n",
    "[\n",
    "  {\"ticker\": \"V2020\", \"year\": 2020, \"quarter\": 1},\n",
    "  {\"ticker\": \"AAPL\", \"year\": 2020, \"quarter\": 1}\n",
    "]\n",
    "// Or, if LLM interprets \"Apple news\" as more general:\n",
    "// [\n",
    "//   {\"ticker\": \"V2020\", \"year\": 2020, \"quarter\": 1},\n",
    "//   {\"ticker\": \"AAPL\", \"year\": null, \"quarter\": null}\n",
    "// ]\n",
    "// The key is both V2020 and AAPL are considered subjects.\n",
    "\"\"\"\n",
    "\n",
    "    user_content = f\"\"\"\n",
    "Original Query:\n",
    "\"{original_query}\"\n",
    "\n",
    "Rule-Based Extraction Results:\n",
    "{rule_based_output_str}\n",
    "\n",
    "Task:\n",
    "Provide the \"Corrected List of Focuses\" as a JSON list of objects based on the instructions.\n",
    "JSON list:\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_completion = groq_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_content,\n",
    "                }\n",
    "            ],\n",
    "            model=LLM_MODEL_NAME,\n",
    "            temperature=0.1, # Lower temperature for more deterministic, factual output\n",
    "            max_tokens=1024, # Adjust as needed\n",
    "            # response_format={\"type\": \"json_object\"} # If supported by Groq and model, helps ensure JSON\n",
    "        )\n",
    "\n",
    "        response_content = chat_completion.choices[0].message.content\n",
    "        \n",
    "        # LLMs sometimes add markdown backticks around JSON, try to strip them\n",
    "        if response_content.startswith(\"```json\"):\n",
    "            response_content = response_content[7:]\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content[:-3]\n",
    "        response_content = response_content.strip()\n",
    "\n",
    "        # print(f\"LLM Raw Response: {response_content}\") # For debugging\n",
    "\n",
    "        llm_focuses_json = json.loads(response_content)\n",
    "        \n",
    "        # Validate and convert to QueryFocus objects\n",
    "        refined_focuses = []\n",
    "        if isinstance(llm_focuses_json, list):\n",
    "            for item in llm_focuses_json:\n",
    "                if isinstance(item, dict) and \"ticker\" in item:\n",
    "                    refined_focuses.append(\n",
    "                        QueryFocus(\n",
    "                            ticker=item.get(\"ticker\"),\n",
    "                            year=item.get(\"year\"), # Handles null\n",
    "                            quarter=item.get(\"quarter\") # Handles null\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Warning: LLM returned an invalid item in the list: {item}\")\n",
    "            return sorted(refined_focuses, key=lambda qf: (\n",
    "                qf.ticker, qf.year or -1, qf.quarter or -1\n",
    "            ))\n",
    "        else:\n",
    "            print(f\"Warning: LLM did not return a list as expected. Response: {llm_focuses_json}\")\n",
    "            return rule_based_focuses # Fallback\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding LLM JSON response: {e}\")\n",
    "        print(f\"LLM Raw Response was: {response_content}\")\n",
    "        return rule_based_focuses # Fallback to rule-based if LLM output is not valid JSON\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during LLM refinement: {e}\")\n",
    "        return rule_based_focuses # Fallback\n",
    "\n",
    "# --- Main processing pipeline ---\n",
    "def process_query_with_llm_refinement(query: str) -> Tuple[List[QueryFocus], str]:\n",
    "    # 1. Rule-based extraction\n",
    "    rule_based_focuses, modified_query_by_rules = extract_structured_metadata(query)\n",
    "    \n",
    "    # 2. LLM refinement\n",
    "    # We pass the original query and the rule_based_focuses to the LLM.\n",
    "    # The modified_query_by_rules is mainly for if you wanted to show the user what's \"left\"\n",
    "    # or for further processing that doesn't need the entities. The LLM works best with the original query.\n",
    "    \n",
    "    if groq_client: # Only call LLM if client is available\n",
    "        print(f\"\\n--- Calling LLM for query: \\\"{query}\\\" ---\")\n",
    "        print(f\"Rule-based output: {rule_based_focuses}\")\n",
    "        refined_focuses = refine_with_llm(query, rule_based_focuses)\n",
    "        print(f\"LLM refined output: {refined_focuses}\")\n",
    "        # The modified query string should still come from the rule-based system,\n",
    "        # as the LLM is focused on correcting the structured (Ticker, Year, Quarter) data.\n",
    "        # If the LLM adds/removes entities, the modified_query_by_rules might become inconsistent\n",
    "        # if not re-calculated. For now, we'll use the rule-based modified_query.\n",
    "        return refined_focuses, modified_query_by_rules\n",
    "    else:\n",
    "        return rule_based_focuses, modified_query_by_rules\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "210e82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "import numpy as np\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "\n",
    "QDRANT_URL_LOCAL = \"http://localhost:6333\"\n",
    "COLLECTION_NAME_LOCAL = \"financial_sp500_local_final_v2\" # Your collection name\n",
    "client = QdrantClient(url=QDRANT_URL_LOCAL)\n",
    "\n",
    "\n",
    "# ------- 1. Focus  ->  Filter --------------------------------------------\n",
    "def focus_to_filter(focus: QueryFocus) -> Filter:\n",
    "    \"\"\"\n",
    "    Convert a single QueryFocus(TKR, year?, qtr?) to a Qdrant payload Filter.\n",
    "    Any attribute that is None is simply omitted, giving you the usual\n",
    "    ‘match everything’ behaviour for that field.\n",
    "    \"\"\"\n",
    "    must_conditions: List[FieldCondition] = [\n",
    "        FieldCondition(\n",
    "            key=\"ticker\",              # payload key in Qdrant\n",
    "            match=MatchValue(value=focus.ticker)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if focus.year is not None:\n",
    "        must_conditions.append(\n",
    "            FieldCondition(\n",
    "                key=\"year\",\n",
    "                match=MatchValue(value=focus.year)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if focus.quarter is not None:\n",
    "        must_conditions.append(\n",
    "            FieldCondition(\n",
    "                key=\"quarter\",\n",
    "                match=MatchValue(value=focus.quarter)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return Filter(must=must_conditions)   # “AND” all present fields\n",
    "\n",
    "\n",
    "# ------- 2. Search with OR-of-focuses -------------------------------------\n",
    "# ------- 3. Separate search for every focus -------------------------------\n",
    "from collections import OrderedDict\n",
    "from dataclasses import asdict           # only for pretty printing\n",
    "\n",
    "def search_qdrant_per_focus(\n",
    "    query_vector,\n",
    "    focuses: List[QueryFocus],\n",
    "    k: int = 10,\n",
    "    with_payload: bool = True,\n",
    "    with_vectors: bool = False,\n",
    "    client: QdrantClient = client,\n",
    "    collection_name: str = COLLECTION_NAME_LOCAL,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run *one* similarity search for *each* QueryFocus so the results stay\n",
    "    strictly separated (e.g., Google 2022 vs. Apple 2021).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    OrderedDict[QueryFocus, list[qdrant_client.http.models.ScoredPoint]]\n",
    "        Keys preserve the input focus order.  Each value is the list of hits\n",
    "        for that focus.\n",
    "    \"\"\"\n",
    "    # Convert numpy vector once\n",
    "    vec = query_vector.tolist() if hasattr(query_vector, \"tolist\") else query_vector\n",
    "\n",
    "    results = OrderedDict()\n",
    "    for focus in focuses:\n",
    "        res = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=vec,\n",
    "            limit=k,\n",
    "            query_filter=focus_to_filter(focus),\n",
    "            with_payload=with_payload,\n",
    "            with_vectors=with_vectors,\n",
    "            timeout=10\n",
    "        )\n",
    "        results[focus] = res\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11417c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calling LLM for query: \"What were the risk factors for Apple in 2024 from the annual report?\" ---\n",
      "Rule-based output: [QueryFocus(ticker='AAPL', year=2024, quarter=None)]\n",
      "Error decoding LLM JSON response: Extra data: line 5 column 1 (char 57)\n",
      "LLM Raw Response was: [\n",
      "  {\"ticker\": \"AAPL\", \"year\": 2024, \"quarter\": null}\n",
      "]\n",
      "\n",
      "Note: The rule-based extraction result is already correct, so the corrected list is identical to the original result.\n",
      "LLM refined output: [QueryFocus(ticker='AAPL', year=2024, quarter=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Serban\\AppData\\Local\\Temp\\ipykernel_28492\\3240241699.py:73: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  res = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focus: QueryFocus(ticker='AAPL', year=2024, quarter=None)\n",
      "  Score: 0.7302, ID: 9dfe42f6-2887-499e-9fe8-b56a5fb2d9b0, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 0, 'global_chunk_id': 'sec_4010304', 'chunk_text': 'Risk Factors The Company\\'s business, reputation, results of operations, financial condition and stock price can be affected by a number of factors, whether currently known or unknown, including those described in Part I, Item 1A of the 2023 Form 10-K and Part II, Item 1A of the Form 10-Q for the quarter ended March 30, 2024 (the \"second quarter 2024 Form 10-Q\"), in each case under the heading \"Risk Factors.\" When any one or more of these risks materialize from time to time, the Company\\'s business, reputation, results of operations, financial condition and stock price can be materially and adversely affected. Except for the risk factor disclosed in Part II, Item 1A of the second quarter 2024 Form 10-Q, which is hereby incorporated by reference into this Part II, Item 1A of this Form 10-Q, there have been no material changes to the Company\\'s risk factors since the 2023 Form 10-K.Apple Inc. | Q3 2024 Form 10-Q | 19Item 2 .Apple Inc. | Q3 2024 Form 10-Q | 19'}\n",
      "  Score: 0.7001, ID: dd1f8b69-33f0-4d76-af2e-3ed6c0d441b8, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Management’s Discussion & Analysis)', 'chunk_sequence_in_section': 12, 'global_chunk_id': 'sec_4010237', 'chunk_text': 'increased during the first quarter of 2024 compared to the same quarter in 2023 due primarily to cost savings and a different Products mix, partially offset by the weakness in foreign currencies relative to the U.S. dollar.Services Gross Margin Services gross margin increased during the first quarter of 2024 compared to the same quarter in 2023 due primarily to higher Services net sales and a different Services mix.Services gross margin percentage increased during the first quarter of 2024 compared to the same quarter in 2023 due primarily to a different Services mix.The Company\\'s future gross margins can be impacted by a variety of factors, as discussed in Part I, Item 1A of the 2023 Form 10-K under the heading \"Risk Factors.\" As a result, the Company believes, in general, gross margins will be subject to volatility and downward pressure.Apple Inc .\" As a result, the Company believes, in general, gross margins will be subject to volatility and downward pressure.Apple Inc. | Q1 2024'}\n",
      "  Score: 0.6986, ID: ddfd80c5-4afb-44a7-ba2b-17fde4cae7a7, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Management’s Discussion & Analysis)', 'chunk_sequence_in_section': 6, 'global_chunk_id': 'sec_4010231', 'chunk_text': \"conditions, including inflation, changes in interest rates, and currency fluctuations, have directly and indirectly impacted, and could in the future materially impact, the Company's results of operations and financial condition.Apple Inc. | Q1 2024 Form 10-Q | 13Segment Operating Performance The following table shows net sales by reportable segment for the three months ended December 30, 2023 and December 31, 2022 (dollars in millions):Three Months Ended December 30,2023December 31,2022Change Net sales by reportable segment:Americas$50,430 $49,278 2 %Europe30,397 27,681 10 %Greater China20,819 23,905 (13)%Japan7,767 6,755 15 %Rest of Asia Pacific10,162 9,535 7 %Total net sales$119,575 $117,154 2 %Americas Americas net sales increased 2% or $1 .2 billion during the first quarter of 2024 compared to the same quarter in 2023 due primarily to higher net sales of Services and i Phone, partially offset by lower net sales of i Pad. The strength in foreign currencies relative to the U.S.\"}\n",
      "  Score: 0.6939, ID: c95bc611-56f9-4206-853e-8dfc35319643, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Management’s Discussion & Analysis)', 'chunk_sequence_in_section': 5, 'global_chunk_id': 'sec_4010257', 'chunk_text': \"the Company's fiscal quarters with calendar quarters, which occurred in the first quarter of 2023. The Company's fiscal years 2024 and 2023 span 52 and 53 weeks, respectively.Macroeconomic Conditions Macroeconomic conditions, including inflation, interest rates and currency fluctuations, have directly and indirectly impacted, and could in the future materially impact, the Company's results of operations and financial condition.Apple Inc .Apple Inc. | Q2 2024 Form 10-Q | 13Segment Operating Performance The following table shows net sales by reportable segment for the three- and six-month periods ended March 30, 2024 and April 1, 2023 (dollars in millions):Three Months Ended Six Months Ended March 30,2024April 1,2023Change March 30,2024April 1,2023Change Net sales by reportable segment:Americas$37,273 $37,784 (1)%$87,703 $87,062 1 %Europe24,123 23,945 1 %54,520 51,626 6 %Greater China16,372 17,812 (8)%37,191 41,717 (11)%Japan6,262 7,176 (13)%14,029 13,931 1 %Rest of Asia Pacific6,723\"}\n",
      "  Score: 0.6847, ID: 876d8828-b898-46fa-b9c1-9f6b15555c09, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Management’s Discussion & Analysis)', 'chunk_sequence_in_section': 5, 'global_chunk_id': 'sec_4010286', 'chunk_text': \"is included in the first fiscal quarter every five or six years to realign the Company's fiscal quarters with calendar quarters, which occurred in the first quarter of 2023. The Company's fiscal years 2024 and 2023 span 52 and 53 weeks, respectively . The Company's fiscal years 2024 and 2023 span 52 and 53 weeks, respectively.Macroeconomic Conditions Macroeconomic conditions, including inflation, interest rates and currency fluctuations, have directly and indirectly impacted, and could in the future materially impact, the Company's results of operations and financial condition.Apple Inc .Apple Inc. | Q3 2024 Form 10-Q | 13Segment Operating Performance The following table shows net sales by reportable segment for the three- and nine-month periods ended June 29, 2024 and July 1, 2023 (dollars in millions):Three Months Ended Nine Months Ended June 29,2024July 1,2023Change June 29,2024July 1,2023Change Net sales by reportable segment:Americas$37,678 $35,383 6 %$125,381 $122,445 2\"}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np, pprint, textwrap\n",
    "\n",
    "MODEL_NAME = \"BAAI/bge-base-en-v1.5\"\n",
    "COLLECTION  = \"financial_sp500_local_final_v2\"\n",
    "TOP_K       = 5\n",
    "\n",
    "# 1. Connect and load encoder\n",
    "enc = SentenceTransformer(MODEL_NAME, device=\"cpu\")   # or \"cuda\"\n",
    "cli = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# 2. Ad-hoc query\n",
    "query = \"What were the risk factors for Apple in 2024 from the annual report?\"\n",
    "focuses, _ = process_query_with_llm_refinement(query)\n",
    "embed = enc.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "\n",
    "hits = search_qdrant_per_focus(\n",
    "    query_vector=embed,\n",
    "    focuses=focuses,\n",
    "    k=TOP_K,\n",
    "    client=cli,\n",
    "    collection_name=COLLECTION\n",
    ")\n",
    "\n",
    "for focus, hits_list in hits.items(): # Renamed 'hits' to 'hits_list' to avoid conflict with outer scope 'hits'\n",
    "    print(\"Focus:\", focus) # Changed from asdict(focus) to focus\n",
    "    for h in hits_list: # Use hits_list here\n",
    "        print(f\"  Score: {h.score:.4f}, ID: {h.id}, Payload: {h.payload}\")\n",
    "        if 'text' in h.payload:\n",
    "            print(\"  Text:\", textwrap.fill(h.payload['text'], width=80))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Assuming your previous code for query_model, client, get_query_embedding, search_qdrant is present)\n",
    "\n",
    "def format_retrieved_context(search_results, max_context_chars=15000):\n",
    "    \"\"\"\n",
    "    Formats the search results from Qdrant into a single string\n",
    "    to be used as context for the LLM.\n",
    "    Also returns a list of source metadata for citation.\n",
    "    \"\"\"\n",
    "    context_parts = []\n",
    "    sources_metadata = []\n",
    "    current_chars = 0\n",
    "\n",
    "    if not search_results:\n",
    "        return \"\", []\n",
    "\n",
    "    for i, hit in enumerate(search_results):\n",
    "        payload = hit.payload\n",
    "        if payload:\n",
    "            chunk_text = payload.get(\"chunk_text\", \"\")\n",
    "            \n",
    "            # Estimate if adding this chunk will exceed the character limit\n",
    "            if current_chars + len(chunk_text) > max_context_chars and context_parts:\n",
    "                print(f\"Context character limit ({max_context_chars}) reached. Stopping context assembly.\")\n",
    "                break # Stop adding more chunks if limit is close\n",
    "\n",
    "            source_info = f\"Source {i+1}:\\n\"\n",
    "            source_info += f\"  Ticker: {payload.get('ticker', 'N/A')}\\n\"\n",
    "            source_info += f\"  Year: {payload.get('year', 'N/A')}\\n\"\n",
    "            source_info += f\"  Filing: {payload.get('filing_type', payload.get('filing_category', 'N/A'))}\\n\"\n",
    "            if payload.get('source_type') == 'sec_filing':  #need a check to see if that is what is called\n",
    "                source_info += f\"  Section: {payload.get('section_name', 'N/A')}\\n\"\n",
    "                source_info += f\"  Item: {payload.get('item', 'N/A')}\\n\"\n",
    "            elif payload.get('source_type') == 'earnings_transcript':\n",
    "                source_info += f\"  Quarter: {payload.get('quarter', 'N/A')}\\n\"\n",
    "                source_info += f\"  Speaker: {payload.get('turn_speaker_simple', 'N/A')}\\n\"\n",
    "                source_info += f\"  Call Section: {payload.get('turn_section', 'N/A')}\\n\"\n",
    "            # source_info += f\"  Original File: {payload.get('original_file_name', 'N/A')}\\n\" # Optional\n",
    "            # source_info += f\"  (Qdrant Score: {hit.score:.4f})\\n\" # Optional, for debugging relevance\n",
    "\n",
    "            context_parts.append(source_info)\n",
    "            context_parts.append(f\"  Content: {chunk_text}\\n---\\n\")\n",
    "            \n",
    "            sources_metadata.append(payload) # Store the full payload for more detailed citation if needed\n",
    "            current_chars += len(source_info) + len(chunk_text) + 5 # Rough estimate for newlines etc.\n",
    "        \n",
    "    return \"\".join(context_parts), sources_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# --- LLM Configuration ---\n",
    "# IMPORTANT: Set your OpenAI API key as an environment variable:\n",
    "# export OPENAI_API_KEY=\"your_api_key_here\"\n",
    "# Or, pass it directly: client_openai = OpenAI(api_key=\"your_api_key_here\")\n",
    "try:\n",
    "    llm_client = OpenAI() # Reads API key from environment variable OPENAI_API_KEY\n",
    "    LLM_MODEL_NAME = \"gpt-3.5-turbo\" # Or \"gpt-4\", \"gpt-4-turbo-preview\", etc.\n",
    "    print(f\"OpenAI client initialized for model: {LLM_MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI client: {e}\")\n",
    "    print(\"Please ensure the 'openai' library is installed and your API key is set.\")\n",
    "    llm_client = None\n",
    "\n",
    "\n",
    "def get_llm_response(query_text: str, context_string: str):\n",
    "    if not llm_client:\n",
    "        raise ValueError(\"LLM client not initialized.\")\n",
    "\n",
    "    system_prompt = \"You are a helpful financial analyst assistant. Answer the user's question based ONLY on the provided context. If the information is not in the context, say you don't know or that the context doesn't provide the answer. Be concise and cite the sources if specific information is used.\"\n",
    "    \n",
    "    user_message = f\"\"\"\n",
    "Context from financial documents:\n",
    "---\n",
    "{context_string}\n",
    "---\n",
    "User Question: {query_text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = llm_client.chat.completions.create(\n",
    "            model=LLM_MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.2 # Lower temperature for more factual, less creative answers\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting response from LLM: {e}\")\n",
    "        return \"Error: Could not get a response from the LLM.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05feba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_rag(user_query: str, top_k_retrieval=5):\n",
    "    print(f\"\\nProcessing query: '{user_query}'\")\n",
    "\n",
    "    # 1. Embed the query\n",
    "    print(\"Embedding user query...\")\n",
    "    try:\n",
    "        # For BGE models, add the recommended prefix for retrieval queries\n",
    "        if \"bge-\" in embedding_model_name.lower(): # embedding_model_name from your setup\n",
    "            query_for_embedding = f\"Represent this sentence for searching relevant passages: {user_query}\"\n",
    "        else:\n",
    "            query_for_embedding = user_query\n",
    "        \n",
    "        query_vector = get_query_embedding(query_for_embedding) # Use your embedding function\n",
    "        print(f\"Query embedded (first 5 dims): {query_vector[:5]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding query: {e}\")\n",
    "        return \"Could not process the query due to an embedding error.\"\n",
    "\n",
    "    # 2. Search Qdrant for relevant chunks\n",
    "    print(f\"Searching Qdrant for top {top_k_retrieval} relevant chunks...\")\n",
    "    try:\n",
    "        search_results = search_qdrant(query_vector, top_k=top_k_retrieval) # Use your Qdrant search\n",
    "        if not search_results:\n",
    "            print(\"No relevant documents found in Qdrant.\")\n",
    "            return \"I could not find relevant information in the documents to answer your question.\"\n",
    "        print(f\"Found {len(search_results)} potential chunks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching Qdrant: {e}\")\n",
    "        return \"Could not process the query due to a database search error.\"\n",
    "\n",
    "    # 3. Format the retrieved context\n",
    "    print(\"Formatting context for LLM...\")\n",
    "    context_string, sources_metadata = format_retrieved_context(search_results)\n",
    "    if not context_string:\n",
    "        print(\"No context could be formatted (perhaps chunks were empty or too large).\")\n",
    "        return \"I found some documents, but could not prepare them to answer your question.\"\n",
    "    \n",
    "    # print(\"\\n--- Context being sent to LLM ---\")\n",
    "    # print(context_string[:1000] + \"...\" if len(context_string) > 1000 else context_string)\n",
    "    # print(\"--- End of Context ---\")\n",
    "\n",
    "    # 4. Get response from LLM\n",
    "    print(\"Getting response from LLM...\")\n",
    "    try:\n",
    "        llm_answer = get_llm_response(user_query, context_string)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM call: {e}\")\n",
    "        return \"An error occurred while trying to generate an answer with the LLM.\"\n",
    "        \n",
    "    # 5. Return the answer (and optionally sources)\n",
    "    # You can enhance this to return structured output\n",
    "    print(\"\\n--- RAG Process Complete ---\")\n",
    "    return llm_answer, sources_metadata\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not LIBRARIES_AVAILABLE or not query_model or not client or not llm_client:\n",
    "        print(\"Exiting: One or more essential components (libraries, models, clients) failed to initialize.\")\n",
    "    else:\n",
    "        # Test queries\n",
    "        queries = [\n",
    "            \"What were Agilent's main business segments in 2018?\",\n",
    "            \"What did Agilent say about the COVID-19 impact in early 2020?\",\n",
    "            \"Summarize the key risks for a major tech company in their 2023 10-K.\",\n",
    "            \"What was Apple's revenue in their latest reported quarter for which data exists?\" # This requires up-to-date data\n",
    "        ]\n",
    "\n",
    "        for q in queries:\n",
    "            answer, sources = answer_query_with_rag(q, top_k_retrieval=3) # Get 3 chunks for context\n",
    "            print(f\"\\n\\nQuery: {q}\")\n",
    "            print(f\"LLM Answer:\\n{answer}\")\n",
    "            \n",
    "            # print(\"\\nSources Used (Payloads):\")\n",
    "            # for i, src_meta in enumerate(sources):\n",
    "            #     print(f\"  Source {i+1} Ticker: {src_meta.get('ticker')}, File: {src_meta.get('original_file_name')}, Section: {src_meta.get('section_name', src_meta.get('turn_section'))}\")\n",
    "            print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
