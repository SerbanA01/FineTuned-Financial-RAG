{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the same model used for indexing\n",
    "# Make sure this matches what generated your .npy files\n",
    "embedding_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "try:\n",
    "    query_model = SentenceTransformer(embedding_model_name)\n",
    "    print(f\"Embedding model '{embedding_model_name}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embedding model: {e}\")\n",
    "    # Handle error: model might not be downloaded, or path is wrong\n",
    "    query_model = None\n",
    "\n",
    "\n",
    "def get_query_embedding(query_text: str):\n",
    "    if not query_model:\n",
    "        raise ValueError(\"Embedding model not loaded.\")\n",
    "    # The model expects a list of texts, even if it's just one\n",
    "    #q_emb = enc.encode(question, normalize_embeddings=True).tolist()\n",
    "    q_emb = query_model.encode(query_text, normalize_embeddings=True).tolist()\n",
    "    return q_emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17a8a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.26.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\serban\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install groq\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70461828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Now it should work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5479dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple, Set, Dict, Any, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Mappings ---\n",
    "COMPANY_TO_TICKER_HINTS = {\n",
    "    \"apple\": \"AAPL\", \"microsoft\": \"MSFT\", \"google\": \"GOOGL\", \"alphabet\": \"GOOGL\",\n",
    "    \"amazon\": \"AMZN\", \"nvidia\": \"NVDA\", \"meta\": \"META\", \"tesla\": \"TSLA\",\n",
    "    \"meta platforms\": \"META\", \"facebook\": \"META\",\n",
    "    \"berkshire hathaway\": \"BRK.B\", \"berkshire hathaway a\": \"BRK.A\",\n",
    "    \"bank of america\": \"BAC\", \"boa\": \"BAC\",\n",
    "    \"boeing\": \"BA\", \"coca cola\": \"KO\", \"coca-cola\": \"KO\", \"cola\": \"KO\", \"coke\": \"KO\",\n",
    "    \"johnson & johnson\": \"JNJ\", \"j&j\": \"JNJ\", \"johnson and johnson\": \"JNJ\",\n",
    "    \"procter & gamble\": \"PG\", \"p&g\": \"PG\", \"procter and gamble\": \"PG\",\n",
    "    \"walmart\": \"WMT\", \"wal-mart\": \"WMT\", \"wally world\": \"WMT\",\n",
    "    \"united parcel service\": \"UPS\", \"ups\": \"UPS\", \"parcel service\": \"UPS\",\n",
    "    \"general electric\": \"GE\", \"ge\": \"GE\",\n",
    "    \"ibm\": \"IBM\", \"international business machines\": \"IBM\",\n",
    "    \"american express\": \"AXP\", \"amex\": \"AXP\",\n",
    "    \"home depot\": \"HD\", \"hd\": \"HD\",\n",
    "    \"mcdonald's\": \"MCD\", \"mcdonalds\": \"MCD\", \"mcd\": \"MCD\", \"mickey d's\": \"MCD\",\n",
    "    \"jpmorgan\": \"JPM\", \"jp morgan\": \"JPM\", \"jpm\": \"JPM\",\n",
    "    \"wells fargo\": \"WFC\", \"citigroup\": \"C\", \"citi\": \"C\",\n",
    "    \"goldman sachs\": \"GS\", \"morgan stanley\": \"MS\",\n",
    "    \"charles schwab\": \"SCHW\", \"schwab\": \"SCHW\",\n",
    "    \"blackrock\": \"BLK\", \"black rock\": \"BLK\",\n",
    "    \"s&p global\": \"SPGI\", \"sandp global\": \"SPGI\",\n",
    "    \"moody's\": \"MCO\", \"moodys\": \"MCO\",\n",
    "    \"intercontinental exchange\": \"ICE\",\n",
    "    \"walt disney\": \"DIS\", \"disney\": \"DIS\", \"disney co\": \"DIS\",\n",
    "    \"comcast\": \"CMCSA\", \"netflix\": \"NFLX\",\n",
    "    \"verizon\": \"VZ\", \"at&t\": \"T\", \"att\": \"T\",\n",
    "    \"t-mobile\": \"TMUS\", \"tmobile\": \"TMUS\",\n",
    "    \"charter\": \"CHTR\", \"fox\": \"FOXA\", \"news corp\": \"NWSA\",\n",
    "    \"honeywell\": \"HON\", \"union pacific\": \"UNP\",\n",
    "    \"3m\": \"MMM\", \"caterpillar\": \"CAT\", \"cat\": \"CAT\",\n",
    "    \"lockheed martin\": \"LMT\", \"raytheon\": \"RTX\",\n",
    "    \"northrop grumman\": \"NOC\", \"northrop\": \"NOC\",\n",
    "    \"illinois tool works\": \"ITW\", \"deere\": \"DE\", \"john deere\": \"DE\",\n",
    "    \"fedex\": \"FDX\", \"fed ex\": \"FDX\",\n",
    "    \"pepsico\": \"PEP\", \"pepsi\": \"PEP\",\n",
    "    \"costco\": \"COST\", \"mondelez\": \"MDLZ\", \"colgate-palmolive\": \"CL\", \"colgate\": \"CL\",\n",
    "    \"kimberly-clark\": \"KMB\", \"general mills\": \"GIS\", \"kraft heinz\": \"KHC\",\n",
    "    \"altria\": \"MO\", \"philip morris\": \"PM\", \"pm\": \"PM\",\n",
    "    \"exxon mobil\": \"XOM\", \"exxon\": \"XOM\", \"mobil\": \"XOM\",\n",
    "    \"chevron\": \"CVX\", \"conocophillips\": \"COP\", \"conoco\": \"COP\",\n",
    "    \"schlumberger\": \"SLB\", \"halliburton\": \"HAL\",\n",
    "    \"eog resources\": \"EOG\", \"marathon petroleum\": \"MPC\", \"marathon\": \"MPC\",\n",
    "    \"phillips 66\": \"PSX\", \"valero\": \"VLO\",\n",
    "    \"kinder morgan\": \"KMI\", \"williams companies\": \"WMB\",\n",
    "    \"devon energy\": \"DVN\",\n",
    "    \"nextera energy\": \"NEE\", \"duke energy\": \"DUK\",\n",
    "    \"southern company\": \"SO\", \"dominion energy\": \"D\",\n",
    "    \"american electric power\": \"AEP\", \"exelon\": \"EXC\",\n",
    "    \"sempra\": \"SRE\", \"xcel energy\": \"XEL\",\n",
    "    \"public service enterprise group\": \"PEG\",\n",
    "    \"consolidated edison\": \"ED\", \"entergy\": \"ETR\", \"firstenergy\": \"FE\",\n",
    "    \"american tower\": \"AMT\", \"prologis\": \"PLD\",\n",
    "    \"crown castle\": \"CCI\", \"equinix\": \"EQIX\", \"public storage\": \"PSA\",\n",
    "    \"simon property\": \"SPG\", \"digital realty\": \"DLR\",\n",
    "    \"welltower\": \"WELL\", \"realty income\": \"O\",\n",
    "    \"alexandria real estate\": \"ARE\", \"avalonbay\": \"AVB\",\n",
    "    \"equity residential\": \"EQR\",\n",
    "    \"linde\": \"LIN\", \"air products\": \"APD\",\n",
    "    \"sherwin-williams\": \"SHW\", \"sherwin williams\": \"SHW\",\n",
    "    \"dow\": \"DOW\", \"dupont\": \"DD\", \"newmont\": \"NEM\",\n",
    "    \"freeport-mcmoran\": \"FCX\", \"freeport\": \"FCX\",\n",
    "    \"international paper\": \"IP\", \"ball\": \"BALL\", \"albemarle\": \"ALB\",\n",
    "    \"vision 2020\": \"V2020\", \"vision2020\": \"V2020\", \"v2020\": \"V2020\",\n",
    "}\n",
    "\n",
    "TICKER_TO_COMPANY_HINTS = {}\n",
    "for name, ticker in COMPANY_TO_TICKER_HINTS.items():\n",
    "    if ticker not in TICKER_TO_COMPANY_HINTS:\n",
    "        TICKER_TO_COMPANY_HINTS[ticker] = name.title()\n",
    "if \"BRK.A\" not in TICKER_TO_COMPANY_HINTS and \"berkshire hathaway a\" in COMPANY_TO_TICKER_HINTS:\n",
    "     TICKER_TO_COMPANY_HINTS[\"BRK.A\"] = COMPANY_TO_TICKER_HINTS[\"berkshire hathaway a\"].title()\n",
    "if \"V2020\" not in TICKER_TO_COMPANY_HINTS and \"vision 2020\" in COMPANY_TO_TICKER_HINTS:\n",
    "     TICKER_TO_COMPANY_HINTS[\"V2020\"] = COMPANY_TO_TICKER_HINTS[\"vision 2020\"].title()\n",
    "\n",
    "\n",
    "TICKER_REGEX = re.compile(r'\\b([A-Z]{1,5}(\\.[A-Z])?)\\b')\n",
    "YEAR_REGEX = re.compile(r'\\b(19[7-9]\\d|20\\d{2})\\b')\n",
    "QUARTER_REGEX = re.compile(\n",
    "    r'\\b(?:Q([1-4])|'\n",
    "    r'(?:Quarter\\s*([1-4]))|'\n",
    "    r'(1st|2nd|3rd|4th)\\s*Quarter|'\n",
    "    r'(first|second|third|fourth)\\s*Quarter)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "QUARTER_WORD_TO_NUM = {\n",
    "    \"1st\": 1, \"first\": 1, \"2nd\": 2, \"second\": 2,\n",
    "    \"3rd\": 3, \"third\": 3, \"4th\": 4, \"fourth\": 4,\n",
    "}\n",
    "\n",
    "class DocType: # Normalized document types\n",
    "    K10 = \"10-K\"\n",
    "    Q10 = \"10-Q\"\n",
    "    EARNINGS_TRANSCRIPT = \"Earnings Transcript\"\n",
    "\n",
    "# Maps keywords to normalized DocType constants\n",
    "DOC_KEYWORD_TO_NORMALIZED_MAP = {\n",
    "    \"10-k\": DocType.K10, \"10k\": DocType.K10,\n",
    "    \"10-K\": DocType.K10, \"10-K filing\": DocType.K10,\n",
    "    \"annual report\": DocType.K10, \"annual filing\": DocType.K10,\n",
    "    \"10-q\": DocType.Q10, \"10q\": DocType.Q10,\n",
    "    \"10-Q\": DocType.Q10, \"10-Q filing\": DocType.Q10,\n",
    "    \"quarterly report\": DocType.Q10, \"quarterly filing\": DocType.Q10,\n",
    "    \"earnings transcript\": DocType.EARNINGS_TRANSCRIPT,\n",
    "    \"earnings call\": DocType.EARNINGS_TRANSCRIPT,\n",
    "    \"financial call\": DocType.EARNINGS_TRANSCRIPT,\n",
    "    \"investor call\": DocType.EARNINGS_TRANSCRIPT,\n",
    "    \"conference call\": DocType.EARNINGS_TRANSCRIPT,\n",
    "    \"transcript\": DocType.EARNINGS_TRANSCRIPT,\n",
    "    \"earnings report\": DocType.EARNINGS_TRANSCRIPT, # Commonly used term\n",
    "}\n",
    "# Regex for finding any of these keywords\n",
    "DOC_TYPE_KEYWORDS_REGEX = re.compile(\n",
    "    r'\\b(?:' + '|'.join(re.escape(k) for k in DOC_KEYWORD_TO_NORMALIZED_MAP.keys()) + r')\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "class EntityType:\n",
    "    TICKER = \"ticker\"; COMPANY = \"company\"; YEAR = \"year\"; QUARTER = \"quarter\"\n",
    "    DOC_TYPE_KEYWORD = \"doc_type_keyword\" # Stores the actual keyword found\n",
    "\n",
    "ENTITY_PRIORITIES = {\n",
    "    EntityType.TICKER: 0, EntityType.YEAR: 1, EntityType.QUARTER: 2,\n",
    "    EntityType.DOC_TYPE_KEYWORD: 3, EntityType.COMPANY: 4\n",
    "}\n",
    "\n",
    "class QueryFocus:\n",
    "    def __init__(self, ticker: str, year: Optional[int] = None, quarter: Optional[int] = None, doc_type: Optional[str] = None):\n",
    "        self.ticker = ticker\n",
    "        self.year = year\n",
    "        self.quarter = quarter # This will be the RAW quarter initially, then finalized\n",
    "        self.doc_type = doc_type # This will be the NORMALIZED doc_type (or None)\n",
    "    def __repr__(self):\n",
    "        return f\"QueryFocus(ticker='{self.ticker}', year={self.year}, quarter={self.quarter}, doc_type='{self.doc_type}')\"\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, QueryFocus) and self.ticker == other.ticker and \\\n",
    "               self.year == other.year and self.quarter == other.quarter and self.doc_type == other.doc_type\n",
    "    def __hash__(self):\n",
    "        return hash((self.ticker, self.year, self.quarter, self.doc_type))\n",
    "\n",
    "def _extract_entities_from_segment_text(segment_text: str) -> List[Dict[str, Any]]:\n",
    "    potential_entities: List[Dict[str, Any]] = []\n",
    "    # Tickers, Companies, Years, Quarters (same as before)\n",
    "    for match in TICKER_REGEX.finditer(segment_text):\n",
    "        ticker_candidate = match.group(1)\n",
    "        if ticker_candidate in TICKER_TO_COMPANY_HINTS:\n",
    "            potential_entities.append({\n",
    "                \"text\": ticker_candidate, \"value\": ticker_candidate, \"type\": EntityType.TICKER,\n",
    "                \"start\": match.start(1), \"end\": match.end(1), \"priority\": ENTITY_PRIORITIES[EntityType.TICKER]\n",
    "            })\n",
    "    for cn_key in sorted(COMPANY_TO_TICKER_HINTS.keys(), key=len, reverse=True):\n",
    "        ticker = COMPANY_TO_TICKER_HINTS[cn_key]\n",
    "        pattern = r'\\b' + re.escape(cn_key) + r'\\b'\n",
    "        for cmatch in re.finditer(pattern, segment_text, re.IGNORECASE):\n",
    "            potential_entities.append({\n",
    "                \"text\": cmatch.group(0), \"value\": ticker, \"type\": EntityType.COMPANY,\n",
    "                \"start\": cmatch.start(0), \"end\": cmatch.end(0), \"priority\": ENTITY_PRIORITIES[EntityType.COMPANY]\n",
    "            })\n",
    "    for ymatch in YEAR_REGEX.finditer(segment_text):\n",
    "        year_str = ymatch.group(1)\n",
    "        potential_entities.append({\n",
    "            \"text\": year_str, \"value\": int(year_str), \"type\": EntityType.YEAR,\n",
    "            \"start\": ymatch.start(1), \"end\": ymatch.end(1), \"priority\": ENTITY_PRIORITIES[EntityType.YEAR]\n",
    "        })\n",
    "    for qmatch in QUARTER_REGEX.finditer(segment_text):\n",
    "        q_val_str = qmatch.group(1) or qmatch.group(2) or qmatch.group(3) or qmatch.group(4)\n",
    "        q_num = None\n",
    "        if q_val_str: q_num = int(q_val_str) if q_val_str.isdigit() else QUARTER_WORD_TO_NUM.get(q_val_str.lower())\n",
    "        if q_num:\n",
    "            potential_entities.append({\n",
    "                \"text\": qmatch.group(0), \"value\": q_num, \"type\": EntityType.QUARTER, # Raw quarter 1-4\n",
    "                \"start\": qmatch.start(0), \"end\": qmatch.end(0), \"priority\": ENTITY_PRIORITIES[EntityType.QUARTER]\n",
    "            })\n",
    "    # Document Type Keywords\n",
    "    for dmatch in DOC_TYPE_KEYWORDS_REGEX.finditer(segment_text):\n",
    "        keyword_found = dmatch.group(0).lower()\n",
    "        normalized_doc_type = DOC_KEYWORD_TO_NORMALIZED_MAP.get(keyword_found)\n",
    "        if normalized_doc_type: # Should always be true due to regex construction\n",
    "            potential_entities.append({\n",
    "                \"text\": dmatch.group(0), \"value\": normalized_doc_type, # Store normalized type\n",
    "                \"type\": EntityType.DOC_TYPE_KEYWORD, # Mark as keyword entity\n",
    "                \"start\": dmatch.start(0), \"end\": dmatch.end(0), \"priority\": ENTITY_PRIORITIES[EntityType.DOC_TYPE_KEYWORD]\n",
    "            })\n",
    "    return potential_entities\n",
    "\n",
    "SENTENCE_DELIMITERS_REGEX = re.compile(r'[.?!]')\n",
    "CLAUSE_DELIMITERS_REGEX = re.compile(r'\\s+(?:and|or|but)\\s+|,', re.IGNORECASE)\n",
    "\n",
    "def extract_structured_metadata(query: str) -> Tuple[List[QueryFocus], str]:\n",
    "    \"\"\"\n",
    "    Rule-based extraction. Creates provisional QueryFocus objects.\n",
    "    - `quarter` will be the raw quarter (1-4) if found.\n",
    "    - `doc_type` will be the normalized DocType (e.g., DocType.K10) if a keyword\n",
    "      for it is found in the segment, otherwise None.\n",
    "    Final quarter/doc_type rules are NOT applied here.\n",
    "    \"\"\"\n",
    "    all_query_focuses_set: Set[QueryFocus] = set()\n",
    "    \n",
    "    glob_potential_entities = _extract_entities_from_segment_text(query)\n",
    "    glob_potential_entities.sort(key=lambda x: (x[\"start\"], x[\"priority\"], -(x[\"end\"] - x[\"start\"])))\n",
    "    \n",
    "    all_extracted_entities_globally: List[Dict[str, Any]] = []\n",
    "    _last_covered_idx = -1\n",
    "    for entity in glob_potential_entities:\n",
    "        if entity[\"start\"] >= _last_covered_idx:\n",
    "            all_extracted_entities_globally.append(entity)\n",
    "            _last_covered_idx = entity[\"end\"]\n",
    "    \n",
    "    # Create global maps for years and quarters\n",
    "    global_years_map: Dict[int, int] = {}\n",
    "    global_quarters_map: Dict[int, int] = {}\n",
    "    \n",
    "    global_years_map = {e[\"value\"]: global_years_map.get(e[\"value\"], 0) + 1 for e in all_extracted_entities_globally if e[\"type\"] == EntityType.YEAR}\n",
    "    global_quarters_map = {e[\"value\"]: global_quarters_map.get(e[\"value\"], 0) + 1 for e in all_extracted_entities_globally if e[\"type\"] == EntityType.QUARTER}\n",
    "            \n",
    "    default_year = list(global_years_map.keys())[0] if len(global_years_map) == 1 else None\n",
    "    default_raw_quarter = list(global_quarters_map.keys())[0] if len(global_quarters_map) == 1 else None # Raw default\n",
    "    \n",
    "    query_segments = []\n",
    "    # ... (segmentation logic remains the same)\n",
    "    initial_sentences = SENTENCE_DELIMITERS_REGEX.split(query)\n",
    "    for sentence_text in initial_sentences:\n",
    "        if not sentence_text.strip(): continue\n",
    "        clauses_text = []\n",
    "        last_clause_split_end = 0\n",
    "        for match in CLAUSE_DELIMITERS_REGEX.finditer(sentence_text):\n",
    "            clauses_text.append(sentence_text[last_clause_split_end:match.start()].strip())\n",
    "            last_clause_split_end = match.end()\n",
    "        clauses_text.append(sentence_text[last_clause_split_end:].strip())\n",
    "        query_segments.extend([c for c in clauses_text if c])\n",
    "    if not query_segments and query.strip(): query_segments.append(query.strip())\n",
    "\n",
    "\n",
    "    for segment_text in query_segments:\n",
    "        if not segment_text.strip(): continue\n",
    "\n",
    "        segment_potential_entities = _extract_entities_from_segment_text(segment_text)\n",
    "        segment_potential_entities.sort(key=lambda x: (x[\"start\"], x[\"priority\"], -(x[\"end\"] - x[\"start\"])))\n",
    "\n",
    "        segment_selected_entities: List[Dict[str, Any]] = []\n",
    "        _last_seg_idx = -1\n",
    "        for entity in segment_potential_entities:\n",
    "            if entity[\"start\"] >= _last_seg_idx:\n",
    "                segment_selected_entities.append(entity)\n",
    "                _last_seg_idx = entity[\"end\"]\n",
    "        \n",
    "        seg_stocks = [e for e in segment_selected_entities if e[\"type\"] in (EntityType.TICKER, EntityType.COMPANY)]\n",
    "        seg_years_entities = sorted([e for e in segment_selected_entities if e[\"type\"] == EntityType.YEAR], key=lambda y: y[\"start\"])\n",
    "        seg_quarters_entities = sorted([e for e in segment_selected_entities if e[\"type\"] == EntityType.QUARTER], key=lambda q: q[\"start\"]) # Raw quarters\n",
    "        seg_doc_type_keyword_entities = sorted([e for e in segment_selected_entities if e[\"type\"] == EntityType.DOC_TYPE_KEYWORD], key=lambda d: d[\"start\"])\n",
    "\n",
    "\n",
    "        if not seg_stocks: continue\n",
    "\n",
    "        # Determine normalized doc_type for the segment (if any keyword present)\n",
    "        # Priority: ET > K10 > Q10 if multiple types of keywords in same segment\n",
    "        segment_normalized_doc_type: Optional[str] = None\n",
    "        doc_types_found_in_segment = {dt_entity['value'] for dt_entity in seg_doc_type_keyword_entities}\n",
    "        \n",
    "        if DocType.EARNINGS_TRANSCRIPT in doc_types_found_in_segment:\n",
    "            segment_normalized_doc_type = DocType.EARNINGS_TRANSCRIPT\n",
    "        elif DocType.K10 in doc_types_found_in_segment:\n",
    "            segment_normalized_doc_type = DocType.K10\n",
    "        elif DocType.Q10 in doc_types_found_in_segment:\n",
    "            segment_normalized_doc_type = DocType.Q10\n",
    "\n",
    "        for stock_entity in seg_stocks:\n",
    "            current_ticker = stock_entity[\"value\"]\n",
    "            assigned_year: Optional[int] = None\n",
    "            assigned_raw_quarter: Optional[int] = None # Store raw quarter (1-4)\n",
    "            \n",
    "            if seg_years_entities:\n",
    "                assigned_year = min(seg_years_entities, key=lambda y: abs(y[\"start\"] - stock_entity[\"start\"]))[\"value\"]\n",
    "            if seg_quarters_entities: # these are raw quarters\n",
    "                assigned_raw_quarter = min(seg_quarters_entities, key=lambda q: abs(q[\"start\"] - stock_entity[\"start\"]))[\"value\"]\n",
    "            \n",
    "            # Apply defaults\n",
    "            if assigned_year is None and default_year is not None:\n",
    "                 assigned_year = default_year\n",
    "            if assigned_raw_quarter is None and default_raw_quarter is not None:\n",
    "                assigned_raw_quarter = default_raw_quarter\n",
    "\n",
    "            all_query_focuses_set.add(QueryFocus(\n",
    "                ticker=current_ticker, \n",
    "                year=assigned_year, \n",
    "                quarter=assigned_raw_quarter, # Store raw quarter\n",
    "                doc_type=segment_normalized_doc_type # Store determined normalized doc type for segment\n",
    "            ))\n",
    "\n",
    "    # --- Final Query Modification (remains mostly the same) ---\n",
    "    modified_query_parts = []\n",
    "    current_pos = 0\n",
    "    # Use all_extracted_entities_globally for query cleaning\n",
    "    for entity in all_extracted_entities_globally:\n",
    "        if entity[\"start\"] > current_pos:\n",
    "            modified_query_parts.append(query[current_pos:entity[\"start\"]])\n",
    "        end_skip = entity[\"end\"]\n",
    "        if entity[\"type\"] in (EntityType.TICKER, EntityType.COMPANY) and \\\n",
    "           not entity[\"text\"].lower().endswith(\"'s\") and \\\n",
    "           entity[\"end\"] + 1 < len(query) and query[entity[\"end\"]] == \"'\" and query[entity[\"end\"]+1].lower() == \"s\":\n",
    "            end_skip = entity[\"end\"] + 2\n",
    "        current_pos = end_skip\n",
    "    if current_pos < len(query): modified_query_parts.append(query[current_pos:])\n",
    "    modified_query = ' '.join(\"\".join(modified_query_parts).split()).strip()\n",
    "\n",
    "    return sorted(list(all_query_focuses_set), key=lambda qf: (\n",
    "        qf.ticker, qf.year or -1, qf.quarter or -1, qf.doc_type or \"\"\n",
    "    )), modified_query\n",
    "\n",
    "\n",
    "# --- Groq LLM Integration ---\n",
    "from groq import Groq\n",
    "\n",
    "try:\n",
    "    groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    if not os.getenv(\"GROQ_API_KEY\"):\n",
    "        raise ValueError(\"GROQ_API_KEY environment variable is not set.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Groq client: {e}\")\n",
    "    groq_client = None\n",
    "\n",
    "LLM_MODEL_NAME = \"llama3-8b-8192\"\n",
    "\n",
    "def format_provisional_output_for_prompt(focuses: List[QueryFocus]) -> str:\n",
    "    if not focuses: return \"Rule-based extraction found no provisional focuses.\"\n",
    "    formatted_str = \"Provisional Rule-Based Extraction (raw quarter, normalized doc_type if keyword found):\\n\"\n",
    "    for i, focus in enumerate(focuses):\n",
    "        year_str = str(focus.year) if focus.year is not None else \"Not specified\"\n",
    "        # Displaying raw quarter as found by rules\n",
    "        quarter_str = \"Q\" + str(focus.quarter) if focus.quarter is not None else \"Not specified\"\n",
    "        doc_type_str = focus.doc_type if focus.doc_type is not None else \"Not specified (no keyword)\"\n",
    "        formatted_str += f\"- Focus {i+1}: Ticker={focus.ticker}, Year={year_str}, Raw Quarter={quarter_str}, Normalized DocType (from keywords)={doc_type_str}\\n\"\n",
    "    return formatted_str.strip()\n",
    "\n",
    "def refine_with_llm(original_query: str, provisional_rule_based_focuses: List[QueryFocus]) -> List[QueryFocus]:\n",
    "\n",
    "    if not groq_client:\n",
    "        print(\"Groq client not initialized. Returning provisional rule-based results.\")\n",
    "        return provisional_rule_based_focuses\n",
    "\n",
    "    provisional_output_str = format_provisional_output_for_prompt(provisional_rule_based_focuses)\n",
    "\n",
    "    # --- UPDATED SYSTEM PROMPT ---\n",
    "    system_prompt = f\"\"\"\n",
    "You are an expert financial data analyst assistant. Your task is to re-evaluate a user's query to produce a definitive, corrected list of financial data focuses.\n",
    "You are provided with a provisional, rule-based extraction; treat it as a HINT, but the user's original query is the absolute source of truth. You MUST override the provisional extraction if it is incorrect or incomplete based on a full reading of the query.\n",
    "\n",
    "Instructions:\n",
    "1.  **Analyze the User's Intent:** Carefully read the ENTIRE user query to understand each distinct request. The query is the ultimate source of truth.\n",
    "2.  **Extract Entities for Each Request:**\n",
    "    a.  **Ticker**: Identify the company ticker.\n",
    "    b.  **Year**: Identify the associated year.\n",
    "    c.  **Raw_Quarter**: Identify the quarter (1, 2, 3, or 4).\n",
    "    d.  **Normalized_DocumentType**: This is a critical step. Search for document type keywords within the same phrase or clause as the company/ticker.\n",
    "        - Keywords for \"{DocType.K10}\": \"10-K\", \"10K\", \"annual report\", \"annual filing\".\n",
    "        - Keywords for \"{DocType.Q10}\": \"10-Q\", \"10Q\", \"quarterly report\", \"quarterly filing\".\n",
    "        - Keywords for \"{DocType.EARNINGS_TRANSCRIPT}\": \"earnings transcript\", \"earnings call\", etc.\n",
    "3.  **Handle Pronouns:** Pay close attention to pronouns like \"its\", \"their\", \"the company's\". Resolve them to the most recent preceding company mentioned. For example, in \"...Apple... see its 10-Q...\", \"its\" refers to Apple.\n",
    "4.  **Strict Association:** You MUST be diligent in linking the document type to the correct company. If a query says \"...Apple's 2023 Q2 10-Q...\", the `normalized_doc_type` for the Apple focus MUST be \"{DocType.Q10}\".\n",
    "5.  **Handle Ambiguity:** If a company is mentioned conversationally (e.g., \"I ate an apple\"), only create a financial data request if it is clearly linked to financial terms like \"10-Q\", \"annual report\", etc.\n",
    "\n",
    "Output Format:\n",
    "Return ONLY a valid JSON object with a \"focuses\" key. \"focuses\" should be an array of objects.\n",
    "Each object MUST have: \"ticker\" (string), \"year\" (integer or null), \"raw_quarter\" (integer 1-4 or null), and \"normalized_doc_type\" (string: \"{DocType.K10}\", \"{DocType.Q10}\", \"{DocType.EARNINGS_TRANSCRIPT}\", or null).\n",
    "\n",
    "Example 1:\n",
    "Query: \"Apple Q1 2022 earnings transcript and Google Q3 2023 10-K.\"\n",
    "Expected JSON:\n",
    "{{\"focuses\": [\n",
    "  {{\"ticker\": \"AAPL\", \"year\": 2022, \"raw_quarter\": 1, \"normalized_doc_type\": \"{DocType.EARNINGS_TRANSCRIPT}\"}},\n",
    "  {{\"ticker\": \"GOOGL\", \"year\": 2023, \"raw_quarter\": 3, \"normalized_doc_type\": \"{DocType.K10}\"}}\n",
    "]}}\n",
    "\n",
    "Example 2 (Coreference Resolution):\n",
    "Query: \"I ate an apple, but I want to see its 2023 Q2 10-Q and also Microsoft's 2022 annual report.\"\n",
    "Expected JSON:\n",
    "{{\"focuses\": [\n",
    "  {{\"ticker\": \"AAPL\", \"year\": 2023, \"raw_quarter\": 2, \"normalized_doc_type\": \"{DocType.Q10}\"}},\n",
    "  {{\"ticker\": \"MSFT\", \"year\": 2022, \"raw_quarter\": null, \"normalized_doc_type\": \"{DocType.K10}\"}}\n",
    "]}}\n",
    "\"\"\"\n",
    "\n",
    "    user_content = f\"\"\"\n",
    "Original Query:\n",
    "\"{original_query}\"\n",
    "\n",
    "Provisional Rule-Based Extraction (this is just a HINT, the Original Query is the source of truth):\n",
    "{provisional_output_str}\n",
    "\n",
    "Task:\n",
    "Provide the \"Corrected List of Focuses\" as a JSON object based on the instructions.\n",
    "Extract ticker, year, raw_quarter (1-4 or null), and normalized_doc_type (\"{DocType.K10}\", \"{DocType.Q10}\", \"{DocType.EARNINGS_TRANSCRIPT}\", or null).\n",
    "The JSON must have a single \"focuses\" key which contains a list of objects.\n",
    "\"\"\"\n",
    "    try:\n",
    "        chat_completion = groq_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            model=LLM_MODEL_NAME, temperature=0.0, max_tokens=1500,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        response_content = chat_completion.choices[0].message.content\n",
    "        if response_content.startswith(\"```json\"): response_content = response_content[7:-3] if response_content.endswith(\"```\") else response_content[7:]\n",
    "        response_content = response_content.strip()\n",
    "\n",
    "        llm_data = json.loads(response_content)\n",
    "        refined_provisional_focuses = []\n",
    "        if isinstance(llm_data, dict) and \"focuses\" in llm_data:\n",
    "            focuses_list = llm_data[\"focuses\"]\n",
    "            if isinstance(focuses_list, list):\n",
    "                for item in focuses_list:\n",
    "                    if isinstance(item, dict) and \"ticker\" in item:\n",
    "                        refined_provisional_focuses.append(QueryFocus(\n",
    "                            ticker=item.get(\"ticker\"),\n",
    "                            year=item.get(\"year\"),\n",
    "                            quarter=item.get(\"raw_quarter\"),\n",
    "                            doc_type=item.get(\"normalized_doc_type\")\n",
    "                        ))\n",
    "                    else: print(f\"Warning: LLM returned an invalid item: {item}\")\n",
    "            elif focuses_list is not None:\n",
    "                print(f\"Warning: LLM 'focuses' field not a list. Response: {llm_data}\")\n",
    "                return provisional_rule_based_focuses\n",
    "        else:\n",
    "            print(f\"Warning: LLM did not return expected format. Response: {llm_data}\")\n",
    "            return provisional_rule_based_focuses\n",
    "        return refined_provisional_focuses\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding LLM JSON: {e}\\nRaw Response: {response_content}\")\n",
    "        return provisional_rule_based_focuses\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM refinement: {e}\")\n",
    "        return provisional_rule_based_focuses\n",
    "\n",
    "def apply_final_rules_to_focuses(provisional_focuses: List[QueryFocus]) -> List[QueryFocus]:\n",
    "    \"\"\"\n",
    "    Applies the strict document type vs. quarter rules.\n",
    "    Modifies the 'quarter' field in each QueryFocus object in place.\n",
    "    \"\"\"\n",
    "    finalized_focuses = []\n",
    "    for focus in provisional_focuses:\n",
    "        final_focus = QueryFocus(focus.ticker, focus.year, focus.quarter, focus.doc_type) # Create a copy\n",
    "\n",
    "        if final_focus.doc_type == DocType.K10:\n",
    "            final_focus.quarter = None  # 10-K never has a quarter\n",
    "        elif final_focus.doc_type == DocType.Q10:\n",
    "            if final_focus.quarter not in [1, 2, 3]: # Includes Q4 or None\n",
    "                final_focus.quarter = None # 10-Q only for Q1, Q2, Q3\n",
    "        # If DocType.EARNINGS_TRANSCRIPT or doc_type is None, quarter (1-4 or None) is kept as is.\n",
    "        finalized_focuses.append(final_focus)\n",
    "    return finalized_focuses\n",
    "\n",
    "def process_query_with_llm_refinement(query: str) -> Tuple[List[QueryFocus], str]:\n",
    "    # 1. Rule-based provisional extraction\n",
    "    provisional_focuses_rules, modified_query_by_rules = extract_structured_metadata(query)\n",
    "    \n",
    "    # 2. LLM refinement of provisional focuses\n",
    "    if groq_client:\n",
    "        print(f\"\\n--- Calling LLM for query: \\\"{query}\\\" ---\")\n",
    "        print(f\"Provisional rule-based output (pre-LLM, pre-final-rules): {provisional_focuses_rules}\")\n",
    "        provisional_focuses_llm = refine_with_llm(query, provisional_focuses_rules)\n",
    "        print(f\"Provisional LLM output (pre-final-rules): {provisional_focuses_llm}\")\n",
    "        # Use LLM output if available, otherwise fallback to rule-based\n",
    "        current_provisional_focuses = provisional_focuses_llm\n",
    "    else:\n",
    "        print(\"LLM client not available, using rule-based provisional output.\")\n",
    "        current_provisional_focuses = provisional_focuses_rules\n",
    "    \n",
    "    # 3. Apply final heuristic rules\n",
    "    final_focuses = apply_final_rules_to_focuses(current_provisional_focuses)\n",
    "    print(f\"Final focuses after applying heuristic rules: {final_focuses}\")\n",
    "    \n",
    "    return final_focuses, modified_query_by_rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9479fe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calling LLM for query: \"I ate an apple, but I want to see its 2023 Q2 10-Q and also Microsoft's 2022 annual report.\" ---\n",
      "Provisional rule-based output (pre-LLM, pre-final-rules): [QueryFocus(ticker='AAPL', year=None, quarter=2, doc_type='None'), QueryFocus(ticker='MSFT', year=2022, quarter=2, doc_type='10-K')]\n",
      "Provisional LLM output (pre-final-rules): [QueryFocus(ticker='AAPL', year=2023, quarter=2, doc_type='10-Q'), QueryFocus(ticker='MSFT', year=2022, quarter=None, doc_type='10-K')]\n",
      "Final focuses after applying heuristic rules: [QueryFocus(ticker='AAPL', year=2023, quarter=2, doc_type='10-Q'), QueryFocus(ticker='MSFT', year=2022, quarter=None, doc_type='10-K')]\n",
      "Final Focuses: [QueryFocus(ticker='AAPL', year=2023, quarter=2, doc_type='10-Q'), QueryFocus(ticker='MSFT', year=2022, quarter=None, doc_type='10-K')]\n",
      "Modified Query: I ate an , but I want to see its and also .\n"
     ]
    }
   ],
   "source": [
    "test_q = \"I ate an apple, but I want to see its 2023 Q2 10-Q and also Microsoft's 2022 annual report.\"\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    final_focuses, modified_query = process_query_with_llm_refinement(test_q)\n",
    "    print(f\"Final Focuses: {final_focuses}\")\n",
    "    print(f\"Modified Query: {modified_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210e82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serban\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from dateutil.parser import parse as date_parse\n",
    "from collections import OrderedDict\n",
    "from typing import List, Optional\n",
    "\n",
    "# Assume all your previous code (parsing, QueryFocus, DocType, etc.) is here.\n",
    "# ...\n",
    "\n",
    "# --- Helper Function to Infer Quarter from Date ---\n",
    "\n",
    "def get_quarter_from_date(date_str: Optional[str]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Infers the calendar quarter (1, 2, 3, or 4) from a date string.\n",
    "    Returns None if the date string is invalid or missing.\n",
    "    \"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        # dateutil.parser is robust and can handle various date formats\n",
    "        dt = date_parse(date_str)\n",
    "        return (dt.month - 1) // 3 + 1\n",
    "    except (ValueError, TypeError):\n",
    "        # Handles cases where date is None, not a string, or un-parseable\n",
    "        return None\n",
    "\n",
    "# --- Step 1: Building the Qdrant Filter (Broad Search) ---\n",
    "\n",
    "def build_single_focus_filter(focus: QueryFocus) -> models.Filter:\n",
    "    \"\"\"\n",
    "    Builds a robust Qdrant filter for a SINGLE QueryFocus object.\n",
    "    This filter is specifically designed to handle the observed data discrepancies.\n",
    "    \"\"\"\n",
    "    must_conditions = []\n",
    "\n",
    "    # Condition: Ticker (Always reliable)\n",
    "    must_conditions.append(\n",
    "        models.FieldCondition(key=\"ticker\", match=models.MatchValue(value=focus.ticker))\n",
    "    )\n",
    "\n",
    "    # Condition: Year (Handles string vs. integer discrepancy)\n",
    "    if focus.year:\n",
    "        # As seen in payloads, 'year' can be '2020' (str) or 2024 (int).\n",
    "        # This 'should' clause ensures we match either type.\n",
    "        must_conditions.append(\n",
    "            models.Filter(\n",
    "                should=[\n",
    "                    models.FieldCondition(key=\"year\", match=models.MatchValue(value=focus.year)),\n",
    "                    models.FieldCondition(key=\"year\", match=models.MatchValue(value=str(focus.year)))\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Condition: Document Type & Quarter (The most nuanced part)\n",
    "    if focus.doc_type == DocType.K10:\n",
    "        # Payloads confirm 10-K is identified by these two fields.\n",
    "        must_conditions.append(models.FieldCondition(key=\"source_type\", match=models.MatchValue(value=\"sec_filing\")))\n",
    "        must_conditions.append(models.FieldCondition(key=\"filing_category\", match=models.MatchValue(value=\"10k\")))\n",
    "        # We do NOT filter on date/quarter, as 'date' is None for 10-Ks.\n",
    "\n",
    "    elif focus.doc_type == DocType.EARNINGS_TRANSCRIPT:\n",
    "        # Payloads confirm this source_type and a reliable 'quarter' field like \"Q1\".\n",
    "        must_conditions.append(models.FieldCondition(key=\"source_type\", match=models.MatchValue(value=\"earnings_transcript\")))\n",
    "        if focus.quarter:\n",
    "            # The 'quarter' field is reliable for transcripts, so we filter directly.\n",
    "            must_conditions.append(\n",
    "                models.FieldCondition(key=\"quarter\", match=models.MatchValue(value=f\"Q{focus.quarter}\"))\n",
    "            )\n",
    "\n",
    "    elif focus.doc_type == DocType.Q10:\n",
    "        # Payloads confirm 10-Q is identified by these two fields.\n",
    "        must_conditions.append(models.FieldCondition(key=\"source_type\", match=models.MatchValue(value=\"sec_filing\")))\n",
    "        must_conditions.append(models.FieldCondition(key=\"filing_category\", match=models.MatchValue(value=\"10q\")))\n",
    "        # CRITICAL: We DO NOT filter by quarter here. 10-Q payloads lack a 'quarter'\n",
    "        # field but have a 'date' field. We will use the date for post-filtering.\n",
    "\n",
    "    return models.Filter(must=must_conditions)\n",
    "\n",
    "\n",
    "def search_qdrant_per_focus(\n",
    "    query_vector,\n",
    "    focuses: List[QueryFocus],\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    k: int = 10\n",
    ") -> OrderedDict[QueryFocus, list[models.ScoredPoint]]:\n",
    "    \"\"\"\n",
    "    Runs one similarity search for each QueryFocus using the broad filter.\n",
    "    This returns initial candidate results that will be refined later.\n",
    "    \"\"\"\n",
    "    vec = query_vector.tolist() if hasattr(query_vector, \"tolist\") else query_vector\n",
    "    initial_results = OrderedDict()\n",
    "\n",
    "    for focus in focuses:\n",
    "        query_filter = build_single_focus_filter(focus)\n",
    "        \n",
    "        try:\n",
    "            res = client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=vec,\n",
    "                limit=k,\n",
    "                query_filter=query_filter,\n",
    "                with_payload=True,\n",
    "                with_vectors=False,\n",
    "                timeout=10\n",
    "            )\n",
    "            initial_results[focus] = res\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching Qdrant for focus {focus}: {e}\")\n",
    "            initial_results[focus] = []\n",
    "            \n",
    "    return initial_results\n",
    "\n",
    "\n",
    "# --- Step 2: Applying the Post-Filter (Precise Filtering) ---\n",
    "\n",
    "def post_filter_results(\n",
    "    initial_results_dict: OrderedDict[QueryFocus, list[models.ScoredPoint]]\n",
    ") -> OrderedDict[QueryFocus, list[models.ScoredPoint]]:\n",
    "    \"\"\"\n",
    "    Applies precise filtering rules AFTER the Qdrant search, specifically for 10-Q quarters.\n",
    "    \"\"\"\n",
    "    final_results_dict = OrderedDict()\n",
    "\n",
    "    for focus, points in initial_results_dict.items():\n",
    "        # The only case requiring post-filtering is a 10-Q with a specific quarter.\n",
    "        if not (focus.doc_type == DocType.Q10 and focus.quarter is not None):\n",
    "            final_results_dict[focus] = points # No post-filtering needed, pass through.\n",
    "            continue\n",
    "\n",
    "        # This is the key logic for 10-Q quarter filtering.\n",
    "        filtered_points = []\n",
    "        for point in points:\n",
    "            # Payloads confirm 'date' is the field to use.\n",
    "            payload_date = point.payload.get(\"date\")\n",
    "            inferred_quarter = get_quarter_from_date(payload_date)\n",
    "            \n",
    "            # Match the inferred quarter with the requested quarter.\n",
    "            if inferred_quarter == focus.quarter:\n",
    "                filtered_points.append(point)\n",
    "        \n",
    "        final_results_dict[focus] = filtered_points\n",
    "\n",
    "    return final_results_dict\n",
    "\n",
    "\n",
    "# --- Main Orchestration Function ---\n",
    "\n",
    "# ==============================================================================\n",
    "# FINAL CODE WITH RELAXATION STRATEGY\n",
    "# ==============================================================================\n",
    "from qdrant_client import QdrantClient, models\n",
    "from dateutil.parser import parse as date_parse\n",
    "from collections import OrderedDict\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import copy # Needed to safely modify focuses\n",
    "\n",
    "# --- Keep all your existing functions ---\n",
    "# get_quarter_from_date, build_single_focus_filter, post_filter_results, etc.\n",
    "# They are the building blocks and do not need to change.\n",
    "# ...\n",
    "\n",
    "# --- NEW Orchestration Function with Relaxation ---\n",
    "# ==============================================================================\n",
    "# ADD THIS ENTIRE BLOCK TO YOUR CODE\n",
    "# It replaces the old process_and_retrieve_with_relaxation function\n",
    "# ==============================================================================\n",
    "import copy\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# This is a new class to hold tiered results\n",
    "class SearchResult:\n",
    "    \"\"\"A container for search results to add metadata like tier.\"\"\"\n",
    "    def __init__(self, point, tier: str):\n",
    "        self.point = point\n",
    "        self.tier = tier # e.g., \"Exact Match\", \"Augmented: Other Years\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"SearchResult(Tier: '{self.tier}', Score: {self.point.score:.4f})\"\n",
    "\n",
    "# This is a new helper function to simplify the main loop\n",
    "def search_and_filter(\n",
    "    query_vector,\n",
    "    focus: \"QueryFocus\",\n",
    "    client: \"QdrantClient\",\n",
    "    collection_name: str,\n",
    "    k: int\n",
    ") -> List[\"models.ScoredPoint\"]:\n",
    "    \"\"\"Helper function to run a single search-and-filter operation.\"\"\"\n",
    "    initial_search_res = search_qdrant_per_focus(\n",
    "        query_vector=query_vector,\n",
    "        focuses=[focus],\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        k=k,\n",
    "    )\n",
    "    final_filtered_res = post_filter_results(initial_search_res)\n",
    "    return final_filtered_res.get(focus, [])\n",
    "\n",
    "\n",
    "# This is the NEW main function that handles both relaxation and augmentation\n",
    "def process_and_retrieve_with_augmentation(\n",
    "    query: str,\n",
    "    client: \"QdrantClient\",\n",
    "    collection_name: str,\n",
    "    query_model,\n",
    "    min_results_k: int = 5,\n",
    ") -> Tuple[Dict[\"QueryFocus\", List[SearchResult]], str]:\n",
    "    \"\"\"\n",
    "    Full pipeline with a two-phase approach:\n",
    "    1. Full Relaxation: Find *any* relevant document if the exact query fails.\n",
    "    2. Result Augmentation: If a query succeeds but returns < k results,\n",
    "       pad the results with slightly relaxed searches.\n",
    "    \"\"\"\n",
    "    original_focuses, modified_query = process_query_with_llm_refinement(query)\n",
    "    \n",
    "    if not original_focuses:\n",
    "        return OrderedDict(), modified_query\n",
    "\n",
    "    print(\"\\n--- Original Parsed Focuses ---\")\n",
    "    for f in original_focuses: print(f)\n",
    "\n",
    "    query_vector = query_model.encode(modified_query, normalize_embeddings=True)\n",
    "    final_results_for_query = OrderedDict()\n",
    "\n",
    "    for original_focus in original_focuses:\n",
    "        print(f\"\\n--- Processing Focus with Augmentation: {original_focus} ---\")\n",
    "        \n",
    "        # --- PHASE 1: Find a base set of results using full relaxation ---\n",
    "        base_results = []\n",
    "        best_focus_found = None\n",
    "        \n",
    "        relaxation_sequence = []\n",
    "        relaxation_sequence.append((original_focus, \"Exact Match\"))\n",
    "        if original_focus.quarter:\n",
    "            focus_no_q = copy.deepcopy(original_focus); focus_no_q.quarter = None\n",
    "            relaxation_sequence.append((focus_no_q, f\"Relaxed: All quarters for {original_focus.year}\"))\n",
    "        if original_focus.year:\n",
    "            focus_no_y = copy.deepcopy(original_focus); focus_no_y.year = None; focus_no_y.quarter = None\n",
    "            relaxation_sequence.append((focus_no_y, \"Relaxed: Most relevant year\"))\n",
    "        if original_focus.doc_type:\n",
    "             focus_no_dt = copy.deepcopy(original_focus); focus_no_dt.doc_type = None; focus_no_dt.year = None; focus_no_dt.quarter = None\n",
    "             relaxation_sequence.append((focus_no_dt, \"Relaxed: Any document type\"))\n",
    "\n",
    "        print(\"  -> Phase 1: Finding best possible results via relaxation...\")\n",
    "        for focus_to_try, message in relaxation_sequence:\n",
    "            print(f\"    - Attempting search with: {focus_to_try}\")\n",
    "            points = search_and_filter(query_vector, focus_to_try, client, collection_name, k=min_results_k)\n",
    "            if points:\n",
    "                print(f\"    - SUCCESS: Found {len(points)} results for '{message}'. This is our base.\")\n",
    "                base_results = [SearchResult(p, tier=message) for p in points]\n",
    "                best_focus_found = focus_to_try\n",
    "                break\n",
    "        \n",
    "        if not base_results:\n",
    "            print(\"  -> Phase 1 FAILED: No results found even after full relaxation.\")\n",
    "            final_results_for_query[original_focus] = []\n",
    "            continue\n",
    "\n",
    "        # --- PHASE 2: Augment results if we have fewer than k ---\n",
    "        if len(base_results) < min_results_k:\n",
    "            print(f\"  -> Phase 2: Augmenting results (found {len(base_results)} of {min_results_k})...\")\n",
    "            \n",
    "            existing_ids = {res.point.id for res in base_results}\n",
    "            \n",
    "            augmentation_sequence = []\n",
    "            if best_focus_found and best_focus_found.quarter:\n",
    "                focus_aug = copy.deepcopy(best_focus_found); focus_aug.quarter = None\n",
    "                augmentation_sequence.append((focus_aug, f\"Augmented: Other quarters from {best_focus_found.year}\"))\n",
    "            if best_focus_found and best_focus_found.year:\n",
    "                focus_aug = copy.deepcopy(best_focus_found); focus_aug.year = None; focus_aug.quarter = None\n",
    "                augmentation_sequence.append((focus_aug, \"Augmented: Other relevant years\"))\n",
    "            if best_focus_found and best_focus_found.doc_type:\n",
    "                 focus_aug = copy.deepcopy(best_focus_found); focus_aug.doc_type = None\n",
    "                 augmentation_sequence.append((focus_aug, \"Augmented: Other document types\"))\n",
    "\n",
    "            for focus_to_try, message in augmentation_sequence:\n",
    "                if len(base_results) >= min_results_k: break\n",
    "\n",
    "                needed = min_results_k - len(base_results)\n",
    "                print(f\"    - Attempting to find {needed} more results with: {focus_to_try}\")\n",
    "                \n",
    "                # Fetch more than needed to account for duplicates\n",
    "                points = search_and_filter(query_vector, focus_to_try, client, collection_name, k=min_results_k * 2)\n",
    "                \n",
    "                new_points_added = 0\n",
    "                for p in points:\n",
    "                    if len(base_results) >= min_results_k: break\n",
    "                    if p.id not in existing_ids:\n",
    "                        base_results.append(SearchResult(p, tier=message))\n",
    "                        existing_ids.add(p.id)\n",
    "                        new_points_added += 1\n",
    "                \n",
    "                if new_points_added > 0:\n",
    "                    print(f\"    - SUCCESS: Added {new_points_added} new results.\")\n",
    "\n",
    "        final_results_for_query[original_focus] = base_results\n",
    "\n",
    "    # 5. Display final results\n",
    "    print(\"\\n\\n--- FINAL TIERED RESULTS ---\")\n",
    "    for focus, results in final_results_for_query.items():\n",
    "        print(f\"\\nResults for Original Request: {focus}\")\n",
    "        if results:\n",
    "            for res in results:\n",
    "                payload = res.point.payload\n",
    "                print(f\"  - Tier: '{res.tier}' | \"\n",
    "                      f\"{payload.get('filing_category') or payload.get('source_type')} \"\n",
    "                      f\"({payload.get('year')}, Date: {payload.get('date')}) | \"\n",
    "                      f\"Score: {res.point.score:.4f}\")\n",
    "        else:\n",
    "            print(\"  No relevant documents could be found.\")\n",
    "            \n",
    "    return final_results_for_query, modified_query\n",
    "\n",
    "#reranking\n",
    "def _get_tier_priority(tier_string: str) -> int:\n",
    "    \"\"\"Assigns a numerical priority (lower is better) to each tier string.\"\"\"\n",
    "    if not tier_string:\n",
    "        return 99\n",
    "    if tier_string == \"Exact Match\":\n",
    "        return 0\n",
    "    if tier_string.startswith(\"Relaxed:\"):\n",
    "        return 1\n",
    "    if tier_string.startswith(\"Augmented:\"):\n",
    "        return 2\n",
    "    return 99\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "def finalize_and_rerank_results(\n",
    "    query: str,\n",
    "    candidate_results: List[\"SearchResult\"],\n",
    "    reranker: \"CrossEncoder\",\n",
    "    final_k: int\n",
    ") -> List[\"SearchResult\"]:\n",
    "\n",
    "    if not candidate_results:\n",
    "        print(\"  -> Reranker received no candidates. Returning empty list.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"  -> Reranking {len(candidate_results)} candidates to select top {final_k}...\")\n",
    "\n",
    "    # 1. Create pairs of [query, document_text] for the model\n",
    "    sentence_pairs = [[query, res.point.payload.get('chunk_text', '')] for res in candidate_results]\n",
    "\n",
    "    # 2. Predict new relevance scores for all candidates\n",
    "    try:\n",
    "        rerank_scores = reranker.predict(sentence_pairs, show_progress_bar=False)\n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR during reranking: {e}. Returning original top-k without reranking.\")\n",
    "        return candidate_results[:final_k]\n",
    "\n",
    "    # 3. Attach the new score and a tier priority to each result object\n",
    "    for res, score in zip(candidate_results, rerank_scores):\n",
    "        res.rerank_score = score\n",
    "        res.tier_priority = _get_tier_priority(res.tier)\n",
    "\n",
    "    # 4. Perform the crucial multi-level sort\n",
    "    #    - Primary sort: by tier_priority (Exact > Relaxed > Augmented)\n",
    "    #    - Secondary sort: by rerank_score (highest score first)\n",
    "    sorted_results = sorted(\n",
    "        candidate_results,\n",
    "        key=lambda x: (x.tier_priority, -x.rerank_score)\n",
    "    )\n",
    "\n",
    "    # 5. Select the final top-k results from the perfectly sorted list\n",
    "    final_top_k = sorted_results[:final_k]\n",
    "    print(f\"  -> Reranking complete. Final list has {len(final_top_k)} items.\")\n",
    "    \n",
    "    return final_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733991d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation\n",
    "from typing import List, Dict, OrderedDict\n",
    "\n",
    "# Assume your SearchResult class is defined and has attributes like:\n",
    "# .point, .tier, .rerank_score\n",
    "\n",
    "def format_context_for_llm(\n",
    "    retrieved_results: Dict[\"QueryFocus\", List[\"SearchResult\"]]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Formats the tiered and reranked search results into a single string of \n",
    "    context for the LLM, with clear source identifiers for citations.\n",
    "    \"\"\"\n",
    "    if not retrieved_results:\n",
    "        return \"No relevant documents were found.\"\n",
    "\n",
    "    context_str = \"CONTEXT:\\n\"\n",
    "    context_str += \"The following document chunks were retrieved as relevant to the user's query:\\n\\n\"\n",
    "    \n",
    "    chunk_index = 1\n",
    "    for focus, results in retrieved_results.items():\n",
    "        if not results:\n",
    "            continue\n",
    "        \n",
    "        # Add a header for the results related to each focus\n",
    "        context_str += f\"--- Documents related to: {focus} ---\\n\"\n",
    "        for res in results:\n",
    "            payload = res.point.payload\n",
    "            \n",
    "            # Create a clear source description\n",
    "            source_info = f\"{payload.get('source_type', '')}\"\n",
    "            if payload.get('filing_category'):\n",
    "                source_info += f\" ({payload.get('filing_category').upper()})\"\n",
    "            if payload.get('year'):\n",
    "                source_info += f\", Year: {payload.get('year')}\"\n",
    "            if payload.get('quarter'):\n",
    "                 source_info += f\", Quarter: {payload.get('quarter')}\"\n",
    "            \n",
    "            # This [CHUNK X] is the key for citations\n",
    "            context_str += f\"[CHUNK {chunk_index}] - Source: {source_info}\\n\"\n",
    "            context_str += f\"Content: \\\"\\\"\\\"\\n{payload.get('chunk_text', '')}\\n\\\"\\\"\\\"\\n\\n\"\n",
    "            chunk_index += 1\n",
    "    \n",
    "    return context_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56755457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yahoo finance price retrieval\n",
    "\n",
    "#words that trigger price retrieval\n",
    "PRICE_KEYWORDS = [\n",
    "    \"price\", \"current price\", \"stock price\", \"share price\", \"trading price\",\n",
    "    \"closing price\", \"last price\", \"latest price\", \"market price\",\n",
    "    \"current value\", \"stock value\", \"share value\", \"valuation\", \"pe ratio\", \"p/e\", \"dividend yield\",\n",
    "    \"market cap\", \"eps multiple\", \"target price\"\n",
    "]\n",
    "\n",
    "def needs_price_retrieval(query: str) -> bool:\n",
    "    query_lower = query.lower()\n",
    "    return any(keyword in query_lower for keyword in PRICE_KEYWORDS)\n",
    "\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "def fetch_price_chunk(ticker: str,\n",
    "                      asof: datetime | None = None) -> dict | None:\n",
    "    \"\"\"\n",
    "    Returns a dict with the exact fields your LLM formatter needs,\n",
    "    or None if the fetch fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        if asof is None:\n",
    "            asof = datetime.utcnow()\n",
    "        # Get last close before `asof`\n",
    "        hist = stock.history(start=asof.date(), end=(asof.date() + timedelta(days=1)))\n",
    "        last_close = float(hist['Close'][-1])  # will raise IndexError if empty\n",
    "        dividend = float(stock.info.get(\"dividendRate\") or 0.0)\n",
    "        return {\n",
    "            \"source_type\": \"market_data\",\n",
    "            \"meta_source\": \"YahooFinance\",\n",
    "            \"ticker\": ticker.upper(),\n",
    "            \"date\": asof.strftime(\"%Y-%m-%d\"),\n",
    "            \"chunk_text\":\n",
    "                f\"Close price on {asof.date()}: ${last_close:,.2f}. \"\n",
    "                f\"Dividend per share (TTM): ${dividend:,.2f}.\"\n",
    "        }\n",
    "    except Exception as exc:\n",
    "        print(f\"[market-data] fetch failed for {ticker}: {exc}\")\n",
    "        return None\n",
    "    \n",
    "#wrap answer in dummy searchresul\n",
    "from qdrant_client.models import ScoredPoint  # only for type compatibility\n",
    "import uuid\n",
    "\n",
    "def make_price_search_result(price_payload: dict) -> SearchResult:\n",
    "    dummy_point = ScoredPoint(\n",
    "        id=str(uuid.uuid4()),\n",
    "        score=1.0,          # irrelevant, we skip rerank\n",
    "        payload=price_payload,\n",
    "        vector=None,\n",
    "        version=0\n",
    "    )\n",
    "    return SearchResult(dummy_point, tier=\"Market Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c198c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq # Or your preferred LLM client\n",
    "\n",
    "# Assume your other functions (format_context_for_llm, etc.) and imports are the same\n",
    "\n",
    "# In your generate_final_answer function, replace the system_prompt with this new one.\n",
    "\n",
    "def generate_final_answer(\n",
    "    original_query: str,\n",
    "    retrieved_results: Dict[\"QueryFocus\", List[\"SearchResult\"]],\n",
    "    llm_client: \"Groq\",\n",
    "    llm_model_name: str = \"llama3-8b-8192\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Takes the retrieved context, formats it, and uses an LLM to generate \n",
    "    a final, citable answer. This version uses the \"Balanced Analyst\" prompt.\n",
    "    \"\"\"\n",
    "    formatted_context = format_context_for_llm(retrieved_results)\n",
    "\n",
    "    if \"No relevant documents\" in formatted_context:\n",
    "        return \"I could not find any relevant documents to answer your query.\"\n",
    "\n",
    "    # --- THE BALANCED ANALYST PROMPT ---\n",
    "    system_prompt = \"\"\"\n",
    "You are a sophisticated Financial Analyst assistant. Your goal is to provide insightful answers based **strictly** on the provided context, acting as a bridge between raw data and human understanding.\n",
    "\n",
    "**Core Directives**\n",
    "\n",
    "1. **Fact First**  \n",
    "    Answer with facts that appear verbatim in the provided [CHUNK X] sections.  \n",
    "    Cite the source chunk for every fact, e.g. [CHUNK 1].  \n",
    "\n",
    "2. **Permitted Inference (Linking Ideas)**  \n",
    "    After the facts, you may highlight logical connections supported by the text.  \n",
    "    Always introduce this step with phrases such as:  \n",
    "      The documents suggest a potential link between   \n",
    "      Based on the context, an implication is that   \n",
    "      Connecting the information from these chunks suggests that   \n",
    "    This sign-posting keeps hard facts separate from analysis.\n",
    "\n",
    "3. **Strict Boundaries (What NOT to do)**  \n",
    "    **DO NOT** use external knowledge; rely only on the context.  \n",
    "    **DO NOT** extrapolate beyond the dates in the text.  \n",
    "    **DO NOT** state an inference as a hard fact.  \n",
    "    If the information is missing, reply: The provided documents do not contain this information.  \n",
    "    Chunks whose `source_type` is **\"market_data\"** (e.g., Yahoo Finance snapshots) may be used **only** for share-price, dividend, or volume statistics, and must be cited like any other chunk.\n",
    "\n",
    "4. **Hypothetical Outlook / Non-binding Analysis** (optional)  \n",
    "    Include this section **only if the user explicitly asks** for forward-looking views, price implications, valuation multiples, or strategic recommendations.  \n",
    "    Begin with:  \n",
    "      This is a hypothetical scenario for educational purposes; it is not investment advice.  \n",
    "    Build simple ratios or projections **derived solely from the provided chunks**.  \n",
    "    If no market-data chunk is present, write:  \n",
    "     No price data provided; unable to compute valuation.  \n",
    "    Prefix every assumption with **Assumption:** and every conclusion with **Implication:**.  \n",
    "    Use probabilistic language (could, may); never express certainty (will).\n",
    "\n",
    "**Example of Good Output**\n",
    "\n",
    "* **Fact:** The companys revenue was $50 billion [CHUNK 2].  \n",
    "* **Fact:** Apples closing share price on 2024-03-29 was $185.56 [CHUNK 3].  \n",
    "* **Fact:** The company also launched three new products in the same quarter [CHUNK 7].  \n",
    "* **Permitted Inference:** The documents suggest a potential link between the three new products [CHUNK 7] and the reported revenue of $50 billion [CHUNK 2].\n",
    "\n",
    "**Hypothetical Outlook / Non-binding Analysis** (include only if the user explicitly requests forward-looking views)\n",
    "\n",
    " This is a hypothetical scenario for educational purposes; it is not investment advice.  \n",
    "Assumption: Services revenue maintains a mid-teens growth rate.  \n",
    "Assumption: Operating expenses grow no faster than 5 % YoY.  \n",
    "Implication: If both assumptions hold, operating margin could expand by ~0.5 percentage points, which historically corresponded to a 4  6 % uplift in valuation multiples.  \n",
    "No price data provided; unable to compute valuation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # The user_prompt and rest of the function remain the same\n",
    "    user_prompt = f\"\"\"{formatted_context}\n",
    "\n",
    "---\n",
    "Based **only** on the context provided above in the [CHUNK X] sections, provide a detailed, synthesized answer to the following user query. Follow all rules, especially the distinction between facts and permitted inferences.\n",
    "\n",
    "**User's Query:** \"{original_query}\"\n",
    "\"\"\"\n",
    "\n",
    "    print(\"\\n--- Sending final context to LLM for synthesis ---\")\n",
    "    \n",
    "    try:\n",
    "        chat_completion = llm_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            model=llm_model_name,\n",
    "            temperature=0.2, # A slight increase to allow for more nuanced language\n",
    "            max_tokens=1400,\n",
    "            top_p=0.9 # Use top-p to allow for more diverse responses\n",
    "        )\n",
    "        print(f\"LLM model loaded successfully \", llm_model_name)\n",
    "        raw_answer = chat_completion.choices[0].message.content\n",
    "        return raw_answer # We still return the raw answer with citations\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during final answer generation: {e}\")\n",
    "        return \"Sorry, an error occurred while trying to generate the answer.\"\n",
    "\n",
    "# Remember to keep using your post_process_answer function in the main script!\n",
    "# final_answer = post_process_answer(raw_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420334ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np, pprint, textwrap\n",
    "\n",
    "MODEL_NAME = \"BAAI/bge-base-en-v1.5\"\n",
    "COLLECTION  = \"financial_sp500_local_final_v2\"\n",
    "TOP_K       = 70\n",
    "\n",
    "# 1. Connect and load encoder\n",
    "enc = SentenceTransformer(MODEL_NAME, device=\"cpu\")   # or \"cuda\"\n",
    "cli = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# 2. Ad-hoc query\n",
    "query = \"Tell me about Apple's Q2 2024? And can you give me some strategic and price recommendations? \"\n",
    "\n",
    "# 3. Search with broad filter\n",
    "#use the functions from above\n",
    "results, modified_query = process_and_retrieve_with_augmentation(\n",
    "    query=query,\n",
    "    client=cli,\n",
    "    collection_name=COLLECTION,\n",
    "    query_model=enc,\n",
    "    min_results_k=TOP_K\n",
    ")\n",
    "\n",
    "#4. rerank the results\n",
    "final_results_for_generation = OrderedDict()\n",
    "RERANKER_PATH = \"ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "reranker_model = CrossEncoder(\n",
    "    model_name_or_path=RERANKER_PATH,\n",
    "    device=\"cpu\"  # or \"cuda\" if you have a GPU\n",
    ")\n",
    "for focus, candidates in results.items():\n",
    "    print(f\"\\nProcessing candidates for focus: {focus}\")\n",
    "    \n",
    "    # Call your new standalone reranking function\n",
    "    final_top_k_list = finalize_and_rerank_results(\n",
    "        query= query,\n",
    "        candidate_results=candidates,\n",
    "        reranker=reranker_model, # Your loaded model\n",
    "        final_k=7\n",
    "    )\n",
    "    final_results_for_generation[focus] = final_top_k_list\n",
    "\n",
    "#inject price if needed\n",
    "if needs_price_retrieval(query):\n",
    "    print(\"[market-data] User query triggers price lookup.\")\n",
    "    for focus, doc_list in final_results_for_generation.items():\n",
    "        # We assume every QueryFocus has a .ticker attribute\n",
    "        ticker = focus.ticker\n",
    "        #fetch the date from the qeury                       f\"({payload.get('year')}, Date: {payload.get('date')}) | \"\n",
    "        #if payload has date use date for price retrieval\n",
    "        \n",
    "        price_payload = fetch_price_chunk(ticker)\n",
    "        if price_payload:\n",
    "            price_res = make_price_search_result(price_payload)\n",
    "            # Push to front so it becomes CHUNK 1 or close to it\n",
    "            doc_list.insert(0, price_res)\n",
    "        else:\n",
    "            print(f\"[market-data] No price data fetched for {ticker}.\")\n",
    "else:\n",
    "    print(\"[market-data] Query contains no valuation keywords; skipping price fetch.\")\n",
    "\n",
    "if final_results_for_generation:\n",
    "    final_answer = generate_final_answer(\n",
    "        original_query=query, # The user's original, full query\n",
    "        retrieved_results=final_results_for_generation,\n",
    "        llm_client=groq_client, # Your initialized Groq client\n",
    "        llm_model_name='llama-3.3-70b-versatile'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" FINAL GENERATED ANSWER\")\n",
    "    print(\"=\"*50)\n",
    "    print(final_answer)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" No answer could be generated as no relevant documents were found.\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6468429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from qdrant_client import QdrantClient\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Load once\n",
    "MODEL_NAME = \"BAAI/bge-base-en-v1.5\"\n",
    "RERANKER_PATH = \"ms-marco-MiniLM-L-6-v2\"\n",
    "COLLECTION  = \"financial_sp500_local_final_v2\"\n",
    "TOP_K = 70\n",
    "\n",
    "enc = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "reranker_model = CrossEncoder(RERANKER_PATH, device=\"cpu\")\n",
    "cli = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "def get_rag_response(query: str) -> str:\n",
    "    results, modified_query = process_and_retrieve_with_augmentation(\n",
    "        query=query,\n",
    "        client=cli,\n",
    "        collection_name=COLLECTION,\n",
    "        query_model=enc,\n",
    "        min_results_k=TOP_K\n",
    "    )\n",
    "\n",
    "    final_results_for_generation = OrderedDict()\n",
    "    for focus, candidates in results.items():\n",
    "        top_k = finalize_and_rerank_results(\n",
    "            query=query,\n",
    "            candidate_results=candidates,\n",
    "            reranker=reranker_model,\n",
    "            final_k=7\n",
    "        )\n",
    "        final_results_for_generation[focus] = top_k\n",
    "\n",
    "    if needs_price_retrieval(query):\n",
    "        for focus, doc_list in final_results_for_generation.items():\n",
    "            ticker = focus.ticker\n",
    "            price_payload = fetch_price_chunk(ticker)\n",
    "            if price_payload:\n",
    "                price_res = make_price_search_result(price_payload)\n",
    "                doc_list.insert(0, price_res)\n",
    "\n",
    "    if final_results_for_generation:\n",
    "        return generate_final_answer(\n",
    "            original_query=query,\n",
    "            retrieved_results=final_results_for_generation,\n",
    "            llm_client=groq_client,\n",
    "            llm_model_name='llama-3.3-70b-versatile'\n",
    "        )\n",
    "    else:\n",
    "        return \" No relevant information found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bc6abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calling LLM for query: \"What is the current stock price of Apple and what are the latest developments in their Q2 2024 earnings?\" ---\n",
      "Provisional rule-based output (pre-LLM, pre-final-rules): [QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='None')]\n",
      "Provisional LLM output (pre-final-rules): [QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='Earnings Transcript')]\n",
      "Final focuses after applying heuristic rules: [QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='Earnings Transcript')]\n",
      "\n",
      "--- Original Parsed Focuses ---\n",
      "QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='Earnings Transcript')\n",
      "\n",
      "--- Processing Focus with Augmentation: QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='Earnings Transcript') ---\n",
      "  -> Phase 1: Finding best possible results via relaxation...\n",
      "    - Attempting search with: QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='Earnings Transcript')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Serban\\AppData\\Local\\Temp\\ipykernel_25088\\1740922586.py:97: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  res = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Attempting search with: QueryFocus(ticker='AAPL', year=2024, quarter=None, doc_type='Earnings Transcript')\n",
      "    - Attempting search with: QueryFocus(ticker='AAPL', year=None, quarter=None, doc_type='Earnings Transcript')\n",
      "    - SUCCESS: Found 70 results for 'Relaxed: Most relevant year'. This is our base.\n",
      "\n",
      "\n",
      "--- FINAL TIERED RESULTS ---\n",
      "\n",
      "Results for Original Request: QueryFocus(ticker='AAPL', year=2024, quarter=2, doc_type='Earnings Transcript')\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2019, Date: Jul 30, 2019, 5:00 p.m. ET) | Score: 0.7315\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.7225\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.7186\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Oct 28, 2021, 5:00 p.m. ET) | Score: 0.7111\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Oct 27, 2022, 5:00 p.m. ET) | Score: 0.7099\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2019, Date: Jul 30, 2019, 5:00 p.m. ET) | Score: 0.7099\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jul 28, 2022, 5:00 p.m. ET) | Score: 0.7056\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jan 27, 2021, 5:00 p.m. ET) | Score: 0.7008\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.7008\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jan 28, 2020, 5:00 p.m. ET) | Score: 0.7003\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Apr 30, 2020, 5:00 p.m. ET) | Score: 0.6997\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Apr 28, 2022, 5:00 p.m. ET) | Score: 0.6994\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Oct 28, 2021, 5:00 p.m. ET) | Score: 0.6970\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6970\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Apr 30, 2020, 5:00 p.m. ET) | Score: 0.6915\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Oct 29, 2020, 5:00 p.m. ET) | Score: 0.6898\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jul 30, 2020, 5:00 p.m. ET) | Score: 0.6884\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Apr 28, 2022, 5:00 p.m. ET) | Score: 0.6880\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jul 28, 2022, 5:00 p.m. ET) | Score: 0.6872\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.6869\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jul 30, 2020, 5:00 p.m. ET) | Score: 0.6857\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Oct 28, 2021, 5:00 p.m. ET) | Score: 0.6847\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jul 27, 2021, 5:00 p.m. ET) | Score: 0.6845\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jan 28, 2020, 5:00 p.m. ET) | Score: 0.6844\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.6844\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2023, Date: Feb 02, 2023, 5:00 p.m. ET) | Score: 0.6833\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Apr 28, 2022, 5:00 p.m. ET) | Score: 0.6820\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6816\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2023, Date: Feb 02, 2023, 5:00 p.m. ET) | Score: 0.6813\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Oct 27, 2022, 5:00 p.m. ET) | Score: 0.6812\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jul 27, 2021, 5:00 p.m. ET) | Score: 0.6808\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2019, Date: Jul 30, 2019, 5:00 p.m. ET) | Score: 0.6804\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Oct 28, 2021, 5:00 p.m. ET) | Score: 0.6804\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2019, Date: Jul 30, 2019, 5:00 p.m. ET) | Score: 0.6791\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jul 28, 2022, 5:00 p.m. ET) | Score: 0.6791\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Oct 29, 2020, 5:00 p.m. ET) | Score: 0.6791\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.6791\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jan 27, 2021, 5:00 p.m. ET) | Score: 0.6791\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Apr 28, 2022, 5:00 p.m. ET) | Score: 0.6791\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Oct 27, 2022, 5:00 p.m. ET) | Score: 0.6787\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6775\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Apr 30, 2020, 5:00 p.m. ET) | Score: 0.6774\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jul 27, 2021, 5:00 p.m. ET) | Score: 0.6772\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6764\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jul 27, 2021, 5:00 p.m. ET) | Score: 0.6762\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jul 28, 2022, 5:00 p.m. ET) | Score: 0.6759\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Oct 27, 2022, 5:00 p.m. ET) | Score: 0.6756\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Apr 28, 2022, 5:00 p.m. ET) | Score: 0.6745\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jul 30, 2020, 5:00 p.m. ET) | Score: 0.6743\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Oct 29, 2020, 5:00 p.m. ET) | Score: 0.6743\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jul 30, 2020, 5:00 p.m. ET) | Score: 0.6738\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jan 27, 2021, 5:00 p.m. ET) | Score: 0.6735\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Apr 30, 2020, 5:00 p.m. ET) | Score: 0.6731\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Oct 28, 2021, 5:00 p.m. ET) | Score: 0.6731\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2023, Date: Feb 02, 2023, 5:00 p.m. ET) | Score: 0.6726\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2019, Date: Jul 30, 2019, 5:00 p.m. ET) | Score: 0.6722\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Apr 30, 2020, 5:00 p.m. ET) | Score: 0.6716\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jul 27, 2021, 5:00 p.m. ET) | Score: 0.6714\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jan 28, 2020, 5:00 p.m. ET) | Score: 0.6711\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jan 28, 2020, 5:00 p.m. ET) | Score: 0.6710\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Oct 28, 2021, 5:00 p.m. ET) | Score: 0.6696\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Oct 29, 2020, 5:00 p.m. ET) | Score: 0.6691\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6689\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jan 28, 2020, 5:00 p.m. ET) | Score: 0.6688\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Jan 27, 2021, 5:00 p.m. ET) | Score: 0.6685\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6682\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2020, Date: Jan 28, 2020, 5:00 p.m. ET) | Score: 0.6680\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2021, Date: Apr 28, 2021, 5:00 p.m. ET) | Score: 0.6680\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.6671\n",
      "  - Tier: 'Relaxed: Most relevant year' | earnings_transcript (2022, Date: Jan 27, 2022, 5:00 p.m. ET) | Score: 0.6671\n",
      "  -> Reranking 70 candidates to select top 7...\n",
      "  -> Reranking complete. Final list has 7 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Serban\\AppData\\Local\\Temp\\ipykernel_25088\\3425746442.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  asof = datetime.utcnow()\n",
      "C:\\Users\\Serban\\AppData\\Local\\Temp\\ipykernel_25088\\3425746442.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  last_close = float(hist['Close'][-1])  # will raise IndexError if empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sending final context to LLM for synthesis ---\n",
      "LLM model loaded successfully  llama-3.3-70b-versatile\n",
      "* **Fact:** The close price of Apple on 2025-06-07 is $203.92 [CHUNK 1].\n",
      "* **Fact:** The dividend per share (TTM) is $1.04 [CHUNK 1].\n",
      "* **Fact:** There is no information provided in the context about the Q2 2024 earnings of Apple, as all the earnings transcripts are from different years (2019, 2020, 2021, and 2022) [CHUNK 2-8].\n",
      "\n",
      "The documents suggest a potential link between the provided market data [CHUNK 1] and the historical earnings transcripts [CHUNK 2-8], but there is no direct information about the Q2 2024 earnings. \n",
      "\n",
      "Based on the context, an implication is that the user may need to look for more recent or specific earnings transcripts to find the latest developments in Apple's Q2 2024 earnings. \n",
      "\n",
      "The provided documents do not contain the information about the current stock price of Apple on the date of the Q2 2024 earnings, nor do they provide any details about the Q2 2024 earnings themselves. \n",
      "\n",
      "If the user is looking for forward-looking views or hypothetical scenarios, please let me know, and I will provide a hypothetical outlook based on the given context.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the current stock price of Apple and what are the latest developments in their Q2 2024 earnings?\"\n",
    "\n",
    "response = get_rag_response(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1248bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample matching points from Qdrant:\n",
      "ID: 004f1367-1d62-4b10-a3f4-8cc8eea369a7, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 8, 'global_chunk_id': 'sec_4010289', 'chunk_text': 'due primarily to lower net sales of i Phone and i Pad. The weakness in the renminbi relative to the U.S. dollar had an unfavorable year-over-year impact on Greater China net sales during the third quarter and first nine months of 2024.Japan Japan net sales increased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to higher net sales of i Phone and i Pad. Year-over-year Japan net sales increased during the first nine months of 2024 due primarily to higher net sales of i Phone, partially offset by lower net sales of Wearables, Home and Accessories. The weakness in the yen relative to the U.S. dollar had an unfavorable year-over-year impact on Japan net sales during the third quarter and first nine months of 2024 . The weakness in the yen relative to the U.S. dollar had an unfavorable year-over-year impact on Japan net sales during the third quarter and first nine months of 2024.Rest of Asia Pacific Rest of Asia Pacific net sales increased during the'}\n",
      "ID: 044f152d-0299-43d5-b98a-fe688d550b2a, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 15, 'global_chunk_id': 'sec_4010296', 'chunk_text': 'in millions):Three Months Ended Nine Months Ended June 29,2024July 1,2023June 29,2024July 1,2023Research and development$8,006 $7,442 $23,605 $22,608 Percentage of total net sales9 %9 %8 %8 %Selling, general and administrative$6,320 $5,973 $19,574 $18,781 Percentage of total net sales7 %7 %7 %6 %Total operating expenses$14,326 $13,415 $43,179 $41,389 Percentage of total net sales17 %16 %15 %14 %Research and Development The growth in research and development (\"R&D\") expense during the third quarter and first nine months of 2024 compared to the same periods in 2023 was driven primarily by increases in headcount-related expenses.Apple Inc .Apple Inc. | Q3 2024 Form 10-Q | 16Selling, General and Administrative Selling, general and administrative expense increased $347 million during the third quarter of 2024 and $793 million during the first nine months of 2024 compared to the same periods in 2023.Provision for Income Taxes Provision for income taxes, effective tax rate and statutory'}\n",
      "ID: 0c8d4684-a0b2-4048-841d-f5e8eb7089dc, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 19, 'global_chunk_id': 'sec_4010300', 'chunk_text': 'annual basis, subject to declaration by the Board of Directors . As of June 29, 2024, the Company\\'s quarterly cash dividend was $0.25 per share. The Company intends to increase its dividend on an annual basis, subject to declaration by the Board of Directors.During the third quarter of 2024, the Company repurchased $26.0 billion of its common stock and paid dividends and dividend equivalents of $3.9 billion.Recent Accounting Pronouncements Income Taxes In December 2023, the Financial Accounting Standards Board (the \"FASB\") issued Accounting Standards Update (\"ASU\") No. 2023-09, Income Taxes (Topic 740): Improvements to Income Tax Disclosures (\"ASU 2023-09\"), which will require the Company to disclose specified additional information in its income tax rate reconciliation and provide additional information for reconciling items that meet a quantitative threshold . ASU 2023-09 will also require the Company to disaggregate its income taxes paid disclosure by federal, state and foreign'}\n",
      "ID: 0f10870b-eea7-4549-bb32-02a325e0901e, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 18, 'global_chunk_id': 'sec_4010243', 'chunk_text': 'to disaggregate its income taxes paid disclosure by federal, state and foreign taxes, with further disaggregation required for significant individual jurisdictions. The Company will adopt ASU 2023-09 in its fourth quarter of 2026. ASU 2023-09 allows for adoption using either a prospective or retrospective transition method.Segment Reporting In November 2023, the FASB issued ASU No . ASU 2023-09 allows for adoption using either a prospective or retrospective transition method.Segment Reporting In November 2023, the FASB issued ASU No. 2023-07, Segment Reporting (Topic 280): Improvements to Reportable Segment Disclosures (\"ASU 2023-07\"), which will require the Company to disclose segment expenses that are significant and regularly provided to the Company\\'s chief operating decision maker (\"CODM\"). In addition, ASU 2023-07 will require the Company to disclose the title and position of its CODM and how the CODM uses segment profit or loss information in assessing segment performance and'}\n",
      "ID: 0f6d45b0-e0a6-4fb7-8748-8de9f7292efe, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 13, 'global_chunk_id': 'sec_4010265', 'chunk_text': 'offset by the weakness in foreign currencies relative to the U.S. dollar.Services Gross Margin Services gross margin and Services gross margin percentage increased during the second quarter and first six months of 2024 compared to the same periods in 2023 due primarily to a different Services mix.The Company\\'s future gross margins can be impacted by a variety of factors, as discussed in Part I, Item 1A of the 2023 Form 10-K under the heading \"Risk Factors.\" As a result, the Company believes, in general, gross margins will be subject to volatility and downward pressure .\" As a result, the Company believes, in general, gross margins will be subject to volatility and downward pressure.Operating Expenses Operating expenses for the three- and six-month periods ended March 30, 2024 and April 1, 2023 were as follows (dollars in millions):Three Months Ended Six Months Ended March 30,2024April 1,2023March 30,2024April 1,2023Research and development$7,903 $7,457 $15,599 $15,166 Percentage of'}\n",
      "ID: 11305930-9240-47ee-8357-b0bab4d33b68, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 0, 'global_chunk_id': 'sec_4010275', 'chunk_text': 'Risk Factors The Company\\'s business, reputation, results of operations, financial condition and stock price can be affected by a number of factors, whether currently known or unknown, including those described in Part I, Item 1A of the 2023 Form 10-K under the heading \"Risk Factors.\" When any one or more of these risks materialize from time to time, the Company\\'s business, reputation, results of operations, financial condition and stock price can be materially and adversely affected. Except as set forth below, there have been no material changes to the Company\\'s risk factors since the 2023 Form 10-K . Except as set forth below, there have been no material changes to the Company\\'s risk factors since the 2023 Form 10-K.The technology industry, including, in some instances, the Company, is subject to intense media, political and regulatory scrutiny, which exposes the Company to increasing regulation, government investigations, legal actions and penalties.From time to time, the Company has'}\n",
      "ID: 1517d44d-e3ed-4a3b-aa53-8b4a5cd89ece, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 12, 'global_chunk_id': 'sec_4010264', 'chunk_text': '$97,126 $92,308 Gross margin percentage:Products36.6 %36.7 %38.3 %36.8 %Services74.6 %71.0 %73.7 %70.9 %Total gross margin percentage46.6 %44.3 %46.2 %43.5 %Products Gross Margin Products gross margin decreased during the second quarter of 2024 compared to the second quarter of 2023 due primarily to lower Products volume and the weakness in foreign currencies relative to the U.S. dollar. Year-over-year Products gross margin was relatively flat during the first six months of 2024 .S. dollar. Year-over-year Products gross margin was relatively flat during the first six months of 2024.Products gross margin percentage was relatively flat during the second quarter of 2024 compared to the second quarter of 2023. Year-over-year Products gross margin percentage increased during the first six months of 2024 due primarily to cost savings, partially offset by the weakness in foreign currencies relative to the U.S. dollar.Services Gross Margin Services gross margin and Services gross margin'}\n",
      "ID: 22a87b88-98f1-4e2b-842e-448398bb577a, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 0, 'global_chunk_id': 'sec_4010246', 'chunk_text': 'Risk Factors The Company\\'s business, reputation, results of operations, financial condition and stock price can be affected by a number of factors, whether currently known or unknown, including those described in Part I, Item 1A of the 2023 Form 10-K under the heading \"Risk Factors.\" When any one or more of these risks materialize from time to time, the Company\\'s business, reputation, results of operations, financial condition and stock price can be materially and adversely affected. Except as set forth below, there have been no material changes to the Company\\'s risk factors since the 2023 Form 10-K . Except as set forth below, there have been no material changes to the Company\\'s risk factors since the 2023 Form 10-K.The technology industry, including, in some instances, the Company, is subject to intense media, political and regulatory scrutiny, which exposes the Company to increasing regulation, government investigations, legal actions and penalties.From time to time, the Company has'}\n",
      "ID: 25a20d9e-7ea5-4eea-a218-5356a8453e76, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 1, 'global_chunk_id': 'sec_4010226', 'chunk_text': '\"predicts,\" \"will,\" \"would,\" \"could,\" \"can,\" \"may,\" and similar terms. Forward-looking statements are not guarantees of future performance and the Company\\'s actual results may differ significantly from the results discussed in the forward-looking statements. Factors that might cause such differences include, but are not limited to, those discussed in Part I, Item 1A of the 2023 Form 10-K under the heading \"Risk Factors . Factors that might cause such differences include, but are not limited to, those discussed in Part I, Item 1A of the 2023 Form 10-K under the heading \"Risk Factors.\" The Company assumes no obligation to revise or update any forward-looking statements for any reason, except as required by law.Unless otherwise stated, all information presented herein is based on the Company\\'s fiscal calendar, and references to particular years, quarters, months or periods refer to the Company\\'s fiscal years ended in September and the associated quarters, months and periods of those'}\n",
      "ID: 25cac400-c74e-4e2b-a397-e98a0dfd3ece, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 20, 'global_chunk_id': 'sec_4010272', 'chunk_text': 'quarter of 2026. ASU 2023-09 allows for adoption using either a prospective or retrospective transition method.Segment Reporting In November 2023, the FASB issued ASU No . ASU 2023-09 allows for adoption using either a prospective or retrospective transition method.Segment Reporting In November 2023, the FASB issued ASU No. 2023-07, Segment Reporting (Topic 280): Improvements to Reportable Segment Disclosures (\"ASU 2023-07\"), which will require the Company to disclose segment expenses that are significant and regularly provided to the Company\\'s chief operating decision maker (\"CODM\"). In addition, ASU 2023-07 will require the Company to disclose the title and position of its CODM and how the CODM uses segment profit or loss information in assessing segment performance and deciding how to allocate resources. The Company will adopt ASU 2023-07 in its fourth quarter of 2025 using a retrospective transition method . The Company will adopt ASU 2023-07 in its fourth quarter of 2025 using a'}\n",
      "ID: 25d1f733-c8b0-4323-856e-2a488b4cd0d0, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 0, 'global_chunk_id': 'sec_4010281', 'chunk_text': 'Management\\'s Discussion and Analysis of Financial Condition and Results of Operations This Item and other sections of this Quarterly Report on Form 10-Q (\"Form 10-Q\") contain forward-looking statements, within the meaning of the Private Securities Litigation Reform Act of 1995, that involve risks and uncertainties. Forward-looking statements provide current expectations of future events based on certain assumptions and include any statement that does not directly relate to any historical or current fact. For example, statements in this Form 10-Q regarding the potential future impact of macroeconomic conditions on the Company\\'s business and results of operations are forward-looking statements. Forward-looking statements can also be identified by words such as \"future,\" \"anticipates,\" \"believes,\" \"estimates,\" \"expects,\" \"intends,\" \"plans,\" \"predicts,\" \"will,\" \"would,\" \"could,\" \"can,\" \"may,\" and similar terms . Forward-looking statements are not guarantees of future performance and the'}\n",
      "ID: 2b439a2b-4a01-4584-b6bc-d61a9fa6ec91, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 10, 'global_chunk_id': 'sec_4010291', 'chunk_text': 'the three- and nine-month periods ended June 29, 2024 and July 1, 2023 (dollars in millions):Three Months Ended Nine Months Ended June 29,2024July 1,2023Change June 29,2024July 1,2023Change Net sales by category:i Phone$39,296 $39,669 (1)%$154,961 $156,778 (1)%Mac7,009 6,840 2 %22,240 21,743 2 %i Pad7,162 5,791 24 %19,744 21,857 (10)%Wearables, Home and Accessories8,097 8,284 (2)%27,963 30,523 (8)%Services24,213 21,213 14 %71,197 62,886 13 %Total net sales$85,777 $81,797 5 %$296,105 $293,787 1 %i Phonei Phone net sales were relatively flat during the third quarter and first nine months of 2024 compared to the same periods in 2023 .Mac Mac net sales increased during the third quarter and first nine months of 2024 compared to the same periods in 2023 due to higher net sales of laptops.i Padi Pad net sales increased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to higher net sales of i Pad Pro and i Pad Air. Year-over-year i Pad net sales decreased'}\n",
      "ID: 3199a2eb-54db-453f-9dac-d9b2e24e1c8e, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 16, 'global_chunk_id': 'sec_4010297', 'chunk_text': \"nine months of 2024 compared to the same periods in 2023.Provision for Income Taxes Provision for income taxes, effective tax rate and statutory federal income tax rate for the three- and nine-month periods ended June 29, 2024 and July 1, 2023 were as follows (dollars in millions):Three Months Ended Nine Months Ended June 29,2024July 1,2023June 29,2024July 1,2023Provision for income taxes$4,046 $2,852 $14,875 $12,699 Effective tax rate15.9 %12.5 %15.8 %14.6 %Statutory federal income tax rate21 %21 %21 %21 %The Company's effective tax rate for the third quarter and first nine months of 2024 was lower than the statutory federal income tax rate due primarily to a lower effective tax rate on foreign earnings, the impact of the U.S .S. federal R&D credit, and tax benefits from share-based compensation, partially offset by state income taxes.The Company's effective tax rate for the third quarter and first nine months of 2024 was higher compared to the same periods in 2023 due primarily to a\"}\n",
      "ID: 32bded38-0211-4257-8d00-ad3c59cb1a4f, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 22, 'global_chunk_id': 'sec_4010274', 'chunk_text': \"consolidated financial statements. There have been no material changes to the Company's critical accounting estimates since the 2023 Form 10-K.Item 3 . There have been no material changes to the Company's critical accounting estimates since the 2023 Form 10-K.\"}\n",
      "ID: 36f823a4-00e4-4f23-a5bd-39229e2c4281, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 12, 'global_chunk_id': 'sec_4010293', 'chunk_text': 'Services net sales increased during the third quarter and first nine months of 2024 compared to the same periods in 2023 due primarily to higher net sales from advertising, the App Store and cloud services.Apple Inc. | Q3 2024 Form 10-Q | 15Gross Margin Products and Services gross margin and gross margin percentage for the three- and nine-month periods ended June 29, 2024 and July 1, 2023 were as follows (dollars in millions):Three Months Ended Nine Months Ended June 29,2024July 1,2023June 29,2024July 1,2023Gross margin:Products$21,761 $21,448 $84,241 $84,205 Services17,917 14,965 52,563 44,516 Total gross margin$39,678 $36,413 $136,804 $128,721 Gross margin percentage:Products35.3 %35.4 %37.5 %36.5 %Services74.0 %70.5 %73.8 %70.8 %Total gross margin percentage46.3 %44.5 %46.2 %43 .3 %35.4 %37.5 %36.5 %Services74.0 %70.5 %73.8 %70.8 %Total gross margin percentage46.3 %44.5 %46.2 %43.8 %Products Gross Margin Products gross margin was relatively flat during the third quarter and first'}\n",
      "ID: 3b9ae542-3431-47e3-85f5-2482aa132c0c, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 3, 'global_chunk_id': 'sec_4010255', 'chunk_text': \"social and governance matters, and details related to the Company's annual meeting of shareholders. The information contained on the websites referenced in this Form 10-Q is not incorporated by reference into this filing. Further, the Company's references to website URLs are intended to be inactive textual references only.Business Seasonality and Product Introductions The Company has historically experienced higher net sales in its first quarter compared to other quarters in its fiscal year due in part to seasonal holiday demand. Additionally, new product and service introductions can significantly impact net sales, cost of sales and operating expenses . Additionally, new product and service introductions can significantly impact net sales, cost of sales and operating expenses. The timing of product introductions can also impact the Company's net sales to its indirect distribution channels as these channels are filled with new inventory following a product launch, and channel\"}\n",
      "ID: 3dda33e4-3254-4eaf-8437-b7b87e03ab0f, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 2, 'global_chunk_id': 'sec_4010248', 'chunk_text': 'Markets Act (the \"DMA\"), including new business terms and alternative fee structures for iOS apps, alternative methods of distribution for iOS apps, alternative payment processing for apps across the Company\\'s operating systems, and additional tools and application programming interfaces (\"APIs\") for developers. Although the Company\\'s compliance plan is intended to address the DMA\\'s obligations, it is still subject to potential challenge by the European Commission or private litigants. In addition, other jurisdictions may seek to require the Company to make changes to its business . In addition, other jurisdictions may seek to require the Company to make changes to its business. While the changes introduced by the Company in the European Union are intended to reduce new privacy and security risks the DMA poses to European Union users, many risks will remain.The Company is also currently subject to antitrust investigations in various jurisdictions around the world, which can result in'}\n",
      "ID: 412916af-bddb-496c-a08a-f2a266ce0a63, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 3, 'global_chunk_id': 'sec_4010284', 'chunk_text': \"referenced in this Form 10-Q is not incorporated by reference into this filing. Further, the Company's references to website URLs are intended to be inactive textual references only . Further, the Company's references to website URLs are intended to be inactive textual references only.Business Seasonality and Product Introductions The Company has historically experienced higher net sales in its first quarter compared to other quarters in its fiscal year due in part to seasonal holiday demand. Additionally, new product and service introductions can significantly impact net sales, cost of sales and operating expenses. The timing of product introductions can also impact the Company's net sales to its indirect distribution channels as these channels are filled with new inventory following a product launch, and channel inventory of an older product often declines as the launch of a newer product approaches. Net sales can also be affected when consumers and distributors anticipate a product\"}\n",
      "ID: 42086f17-3fb4-474a-8df6-6cfc45958d4a, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 2, 'global_chunk_id': 'sec_4010277', 'chunk_text': 'business terms and alternative fee structures for iOS apps, alternative methods of distribution for iOS apps, alternative payment processing for apps across the Company\\'s operating systems, and additional tools and application programming interfaces (\"APIs\") for developers. Although the Company\\'s compliance plan is intended to address the DMA\\'s obligations, it has been challenged by the Commission and may be challenged further by private litigants. In addition, other jurisdictions may seek to require the Company to make changes to its business. While the changes introduced by the Company in the EU are intended to reduce new privacy and security risks the DMA poses to EU users, many risks will remain . While the changes introduced by the Company in the EU are intended to reduce new privacy and security risks the DMA poses to EU users, many risks will remain.The Company is also currently subject to antitrust investigations and litigation in various jurisdictions around the world, which'}\n",
      "ID: 45477e7b-1808-4d75-9286-3c119dbfb33a, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 18, 'global_chunk_id': 'sec_4010299', 'chunk_text': \"2023 Form 10-K, except for manufacturing purchase obligations.Manufacturing Purchase Obligations The Company utilizes several outsourcing partners to manufacture subassemblies for the Company's products and to perform final assembly and testing of finished products. The Company also obtains individual components for its products from a wide variety of individual suppliers. As of June 29, 2024, the Company had manufacturing purchase obligations of $38.4 billion, with $38.3 billion payable within 12 months.Capital Return Program In addition to its contractual cash requirements, the Company has authorized share repurchase programs. The programs do not obligate the Company to acquire a minimum amount of shares. As of June 29, 2024, the Company's quarterly cash dividend was $0.25 per share. The Company intends to increase its dividend on an annual basis, subject to declaration by the Board of Directors . As of June 29, 2024, the Company's quarterly cash dividend was $0.25 per share. The\"}\n",
      "ID: 46d728e6-709c-4554-9228-961c6f48307d, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 9, 'global_chunk_id': 'sec_4010290', 'chunk_text': 'on Japan net sales during the third quarter and first nine months of 2024.Rest of Asia Pacific Rest of Asia Pacific net sales increased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to higher net sales of Services, i Phone and i Pad. Year-over-year Rest of Asia Pacific net sales were relatively flat during the first nine months of 2024. The weakness in foreign currencies relative to the U.S. dollar had a net unfavorable year-over-year impact on Rest of Asia Pacific net sales during the third quarter and first nine months of 2024.Apple Inc .S. dollar had a net unfavorable year-over-year impact on Rest of Asia Pacific net sales during the third quarter and first nine months of 2024.Apple Inc. | Q3 2024 Form 10-Q | 14Products and Services Performance The following table shows net sales by category for the three- and nine-month periods ended June 29, 2024 and July 1, 2023 (dollars in millions):Three Months Ended Nine Months Ended June 29,2024July'}\n",
      "ID: 49081347-8b59-4b06-9267-bf95dee67970, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 1, 'global_chunk_id': 'sec_4010247', 'chunk_text': 'which exposes the Company to increasing regulation, government investigations, legal actions and penalties.From time to time, the Company has made changes to its App Store, including actions taken in response to litigation, competition, market conditions and legal and regulatory requirements. The Company expects to make further business changes in the future. For example, in the U.S. the Company has implemented changes to how developers communicate with consumers within apps on the U.S. storefront of the iOS and i PadOS App Store regarding alternative purchasing mechanisms.Apple Inc .S. storefront of the iOS and i PadOS App Store regarding alternative purchasing mechanisms.Apple Inc. | Q1 2024 Form 10-Q | 19In January 2024, the Company announced changes to iOS, the App Store and Safari in the European Union to comply with the Digital Markets Act (the \"DMA\"), including new business terms and alternative fee structures for iOS apps, alternative methods of distribution for iOS apps,'}\n",
      "ID: 4b44a7e8-a03f-4722-8b3a-88808a2260cd, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 13, 'global_chunk_id': 'sec_4010238', 'chunk_text': 'Inc .\" As a result, the Company believes, in general, gross margins will be subject to volatility and downward pressure.Apple Inc. | Q1 2024 Form 10-Q | 16Operating Expenses Operating expenses for the three months ended December 30, 2023 and December 31, 2022 were as follows (dollars in millions):Three Months Ended December 30,2023December 31,2022Research and development$7,696 $7,709 Percentage of total net sales6 %7 %Selling, general and administrative$6,786 $6,607 Percentage of total net sales6 %6 %Total operating expenses$14,482 $14,316 Percentage of total net sales12 %12 %Research and Development Research and development (\"R&D\") expense was relatively flat during the first quarter of 2024 compared to the same quarter in 2023.Selling, General and Administrative Selling, general and administrative expense increased 3% or $179 million during the first quarter of 2024 compared to the same quarter in 2023 .Selling, General and Administrative Selling, general and administrative expense'}\n",
      "ID: 4b5c45f2-ee1f-433c-9dd4-b6a99d1f9f81, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 21, 'global_chunk_id': 'sec_4010302', 'chunk_text': 'in assessing segment performance and deciding how to allocate resources . The Company will adopt ASU 2023-07 in its fourth quarter of 2025 using a retrospective transition method.Critical Accounting Estimates The preparation of financial statements and related disclosures in conformity with GAAP and the Company\\'s discussion and analysis of its financial condition and operating results require the Company\\'s management to make judgments, assumptions and estimates that affect the amounts reported. Note 1, \"Summary of Significant Accounting Policies\" of the Notes to Condensed Consolidated Financial Statements in Part I, Item 1 of this Form 10-Q and in the Notes to Consolidated Financial Statements in Part II, Item 8 of the 2023 Form 10-K describe the significant accounting policies and methods used in the preparation of the Company\\'s condensed consolidated financial statements. There have been no material changes to the Company\\'s critical accounting estimates since the 2023 Form 10-K.Item'}\n",
      "ID: 4ba959a8-cc07-4bf5-a037-b423acdebf2e, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 2, 'global_chunk_id': 'sec_4010283', 'chunk_text': 'months and periods of those fiscal years.The following discussion should be read in conjunction with the 2023 Form 10-K filed with the U.S .The following discussion should be read in conjunction with the 2023 Form 10-K filed with the U.S. Securities and Exchange Commission (the \"SEC\") and the condensed consolidated financial statements and accompanying notes included in Part I, Item 1 of this Form 10-Q.Available Information The Company periodically provides certain information for investors on its corporate website, www.apple.com, and its investor relations website, investor.apple.com. This includes press releases and other information about financial performance, information on environmental, social and governance matters, and details related to the Company\\'s annual meeting of shareholders. The information contained on the websites referenced in this Form 10-Q is not incorporated by reference into this filing. Further, the Company\\'s references to website URLs are intended to be'}\n",
      "ID: 5089b7b3-25af-436b-9b96-9fcce259e227, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-08-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-08-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 7, 'global_chunk_id': 'sec_4010288', 'chunk_text': 'impact on Americas net sales during the first nine months of 2024.Europe Europe net sales increased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to higher net sales of Services and i Pad. The weakness in foreign currencies relative to the U.S. dollar had a net unfavorable year-over-year impact on Europe net sales during the third quarter of 2024. Year-over-year Europe net sales increased during the first nine months of 2024 due primarily to higher net sales of Services and i Phone, partially offset by lower net sales of Wearables, Home and Accessories .Greater China Greater China net sales decreased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to lower net sales of i Phone. Year-over-year Greater China net sales decreased during the first nine months of 2024 due primarily to lower net sales of i Phone and i Pad. The weakness in the renminbi relative to the U.S. dollar had an unfavorable year-over-year'}\n",
      "ID: 525378a7-fa04-4b4e-8efb-618aa0a0afa9, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 16, 'global_chunk_id': 'sec_4010241', 'chunk_text': \"obligations.Manufacturing Purchase Obligations The Company utilizes several outsourcing partners to manufacture subassemblies for the Company's products and to perform final assembly and testing of finished products. The Company also obtains individual components for its products from a wide variety of individual suppliers . The Company also obtains individual components for its products from a wide variety of individual suppliers. As of December 30, 2023, the Company had manufacturing purchase obligations of $38.0 billion, with $37.9 billion payable within 12 months.Apple Inc. | Q1 2024 Form 10-Q | 17Capital Return Program In addition to its contractual cash requirements, the Company has an authorized share repurchase program. The program does not obligate the Company to acquire a minimum amount of shares. As of December 30, 2023, the Company's quarterly cash dividend was $0.24 per share. The Company intends to increase its dividend on an annual basis, subject to declaration by the\"}\n",
      "ID: 543d8a59-0415-4ff1-a644-9ba7c80ced2a, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '1A', 'section_name': 'Risk Factors', 'chunk_sequence_in_section': 3, 'global_chunk_id': 'sec_4010278', 'chunk_text': 'risks will remain.The Company is also currently subject to antitrust investigations and litigation in various jurisdictions around the world, which can result in legal proceedings and claims against the Company that could, individually or in the aggregate, have a materially adverse impact on the Company\\'s business, results of operations and financial condition. For example, the Company is subject to civil antitrust lawsuits in the U.S. alleging monopolization or attempted monopolization in the markets for \"performance smartphones\" and \"smartphones\" generally in violation of U.S. antitrust laws. In addition, the Company is the subject of investigations in Europe and other jurisdictions relating to App Store terms and conditions .S. antitrust laws. In addition, the Company is the subject of investigations in Europe and other jurisdictions relating to App Store terms and conditions. If such investigations or litigation are resolved against the Company, the Company can be exposed to'}\n",
      "ID: 5b754494-a266-4f9d-97a2-bd9e5a9aa3c4, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-05-03.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-05-03', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 7, 'global_chunk_id': 'sec_4010259', 'chunk_text': 'quarter of 2024 compared to the second quarter of 2023, with higher net sales of Services offset by lower net sales of i Phone. The weakness in foreign currencies relative to the U.S. dollar had a net unfavorable year-over-year impact on Europe net sales during the second quarter of 2024. Year-over-year Europe net sales increased during the first six months of 2024 due primarily to higher net sales of i Phone and Services, partially offset by lower net sales of i Pad . Year-over-year Europe net sales increased during the first six months of 2024 due primarily to higher net sales of i Phone and Services, partially offset by lower net sales of i Pad.Greater China Greater China net sales decreased during the second quarter and first six months of 2024 compared to the same periods in 2023 due primarily to lower net sales of i Phone and i Pad. The weakness in the renminbi relative to the U.S. dollar had an unfavorable year-over-year impact on Greater China net sales during the second'}\n",
      "ID: 5d7a7aaa-6b3e-42fe-b824-972623a55c66, Payload: {'source_type': 'sec_filing', 'filing_category': '10q', 'original_file_name': '2024_2024-02-02.json', 'ticker': 'AAPL', 'year': 2024, 'cik': '0000320193', 'date': '2024-02-02', 'filing_type': '10-Q', 'item': '2', 'section_name': 'MD&A (Managements Discussion & Analysis)', 'chunk_sequence_in_section': 0, 'global_chunk_id': 'sec_4010225', 'chunk_text': 'Management\\'s Discussion and Analysis of Financial Condition and Results of Operations This Item and other sections of this Quarterly Report on Form 10-Q (\"Form 10-Q\") contain forward-looking statements, within the meaning of the Private Securities Litigation Reform Act of 1995, that involve risks and uncertainties . Forward-looking statements provide current expectations of future events based on certain assumptions and include any statement that does not directly relate to any historical or current fact. For example, statements in this Form 10-Q regarding the potential future impact of macroeconomic conditions on the Company\\'s business and results of operations are forward-looking statements. Forward-looking statements can also be identified by words such as \"future,\" \"anticipates,\" \"believes,\" \"estimates,\" \"expects,\" \"intends,\" \"plans,\" \"predicts,\" \"will,\" \"would,\" \"could,\" \"can,\" \"may,\" and similar terms. Forward-looking statements are not guarantees of future performance and the'}\n"
     ]
    }
   ],
   "source": [
    "# Example: Get some points that should be AAPL 2020 10-K\n",
    "sample_filter_fixed = models.Filter(\n",
    "    must=[\n",
    "        models.FieldCondition(key=\"ticker\", match=models.MatchValue(value=\"AAPL\")),\n",
    "        models.FieldCondition(key=\"year\", match=models.MatchValue(value=2024)),\n",
    "        models.FieldCondition(key=\"source_type\", match=models.MatchValue(value=\"sec_filing\")),\n",
    "        models.FieldCondition(key=\"filing_category\", match=models.MatchValue(value=\"10q\"))\n",
    "\n",
    "    ]\n",
    ")\n",
    "# Then use this sample_filter_fixed with cli.scroll\n",
    "# ... (rest of your scroll code)\n",
    "try:\n",
    "    scroll_response = cli.scroll(\n",
    "        collection_name=COLLECTION,\n",
    "        scroll_filter=sample_filter_fixed,\n",
    "        limit=30,\n",
    "        with_payload=True\n",
    "    )\n",
    "    if scroll_response[0]: # scroll_response is a tuple (points, next_offset)\n",
    "        print(\"Sample matching points from Qdrant:\")\n",
    "        for point in scroll_response[0]:\n",
    "            print(f\"ID: {point.id}, Payload: {point.payload}\")\n",
    "    else:\n",
    "        print(\"No points found in Qdrant matching the sample filter directly via scroll.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error scrolling Qdrant: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Assuming your previous code for query_model, client, get_query_embedding, search_qdrant is present)\n",
    "\n",
    "def format_retrieved_context(search_results, max_context_chars=15000):\n",
    "    \"\"\"\n",
    "    Formats the search results from Qdrant into a single string\n",
    "    to be used as context for the LLM.\n",
    "    Also returns a list of source metadata for citation.\n",
    "    \"\"\"\n",
    "    context_parts = []\n",
    "    sources_metadata = []\n",
    "    current_chars = 0\n",
    "\n",
    "    if not search_results:\n",
    "        return \"\", []\n",
    "\n",
    "    for i, hit in enumerate(search_results):\n",
    "        payload = hit.payload\n",
    "        if payload:\n",
    "            chunk_text = payload.get(\"chunk_text\", \"\")\n",
    "            \n",
    "            # Estimate if adding this chunk will exceed the character limit\n",
    "            if current_chars + len(chunk_text) > max_context_chars and context_parts:\n",
    "                print(f\"Context character limit ({max_context_chars}) reached. Stopping context assembly.\")\n",
    "                break # Stop adding more chunks if limit is close\n",
    "\n",
    "            source_info = f\"Source {i+1}:\\n\"\n",
    "            source_info += f\"  Ticker: {payload.get('ticker', 'N/A')}\\n\"\n",
    "            source_info += f\"  Year: {payload.get('year', 'N/A')}\\n\"\n",
    "            source_info += f\"  Filing: {payload.get('filing_type', payload.get('filing_category', 'N/A'))}\\n\"\n",
    "            if payload.get('source_type') == 'sec_filing':  #need a check to see if that is what is called\n",
    "                source_info += f\"  Section: {payload.get('section_name', 'N/A')}\\n\"\n",
    "                source_info += f\"  Item: {payload.get('item', 'N/A')}\\n\"\n",
    "            elif payload.get('source_type') == 'earnings_transcript':\n",
    "                source_info += f\"  Quarter: {payload.get('quarter', 'N/A')}\\n\"\n",
    "                source_info += f\"  Speaker: {payload.get('turn_speaker_simple', 'N/A')}\\n\"\n",
    "                source_info += f\"  Call Section: {payload.get('turn_section', 'N/A')}\\n\"\n",
    "            # source_info += f\"  Original File: {payload.get('original_file_name', 'N/A')}\\n\" # Optional\n",
    "            # source_info += f\"  (Qdrant Score: {hit.score:.4f})\\n\" # Optional, for debugging relevance\n",
    "\n",
    "            context_parts.append(source_info)\n",
    "            context_parts.append(f\"  Content: {chunk_text}\\n---\\n\")\n",
    "            \n",
    "            sources_metadata.append(payload) # Store the full payload for more detailed citation if needed\n",
    "            current_chars += len(source_info) + len(chunk_text) + 5 # Rough estimate for newlines etc.\n",
    "        \n",
    "    return \"\".join(context_parts), sources_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# --- LLM Configuration ---\n",
    "# IMPORTANT: Set your OpenAI API key as an environment variable:\n",
    "# export OPENAI_API_KEY=\"your_api_key_here\"\n",
    "# Or, pass it directly: client_openai = OpenAI(api_key=\"your_api_key_here\")\n",
    "try:\n",
    "    llm_client = OpenAI() # Reads API key from environment variable OPENAI_API_KEY\n",
    "    LLM_MODEL_NAME = \"gpt-3.5-turbo\" # Or \"gpt-4\", \"gpt-4-turbo-preview\", etc.\n",
    "    print(f\"OpenAI client initialized for model: {LLM_MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI client: {e}\")\n",
    "    print(\"Please ensure the 'openai' library is installed and your API key is set.\")\n",
    "    llm_client = None\n",
    "\n",
    "\n",
    "def get_llm_response(query_text: str, context_string: str):\n",
    "    if not llm_client:\n",
    "        raise ValueError(\"LLM client not initialized.\")\n",
    "\n",
    "    system_prompt = \"You are a helpful financial analyst assistant. Answer the user's question based ONLY on the provided context. If the information is not in the context, say you don't know or that the context doesn't provide the answer. Be concise and cite the sources if specific information is used.\"\n",
    "    \n",
    "    user_message = f\"\"\"\n",
    "Context from financial documents:\n",
    "---\n",
    "{context_string}\n",
    "---\n",
    "User Question: {query_text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = llm_client.chat.completions.create(\n",
    "            model=LLM_MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.2 # Lower temperature for more factual, less creative answers\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting response from LLM: {e}\")\n",
    "        return \"Error: Could not get a response from the LLM.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05feba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_rag(user_query: str, top_k_retrieval=5):\n",
    "    print(f\"\\nProcessing query: '{user_query}'\")\n",
    "\n",
    "    # 1. Embed the query\n",
    "    print(\"Embedding user query...\")\n",
    "    try:\n",
    "        # For BGE models, add the recommended prefix for retrieval queries\n",
    "        if \"bge-\" in embedding_model_name.lower(): # embedding_model_name from your setup\n",
    "            query_for_embedding = f\"Represent this sentence for searching relevant passages: {user_query}\"\n",
    "        else:\n",
    "            query_for_embedding = user_query\n",
    "        \n",
    "        query_vector = get_query_embedding(query_for_embedding) # Use your embedding function\n",
    "        print(f\"Query embedded (first 5 dims): {query_vector[:5]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding query: {e}\")\n",
    "        return \"Could not process the query due to an embedding error.\"\n",
    "\n",
    "    # 2. Search Qdrant for relevant chunks\n",
    "    print(f\"Searching Qdrant for top {top_k_retrieval} relevant chunks...\")\n",
    "    try:\n",
    "        search_results = search_qdrant(query_vector, top_k=top_k_retrieval) # Use your Qdrant search\n",
    "        if not search_results:\n",
    "            print(\"No relevant documents found in Qdrant.\")\n",
    "            return \"I could not find relevant information in the documents to answer your question.\"\n",
    "        print(f\"Found {len(search_results)} potential chunks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching Qdrant: {e}\")\n",
    "        return \"Could not process the query due to a database search error.\"\n",
    "\n",
    "    # 3. Format the retrieved context\n",
    "    print(\"Formatting context for LLM...\")\n",
    "    context_string, sources_metadata = format_retrieved_context(search_results)\n",
    "    if not context_string:\n",
    "        print(\"No context could be formatted (perhaps chunks were empty or too large).\")\n",
    "        return \"I found some documents, but could not prepare them to answer your question.\"\n",
    "    \n",
    "    # print(\"\\n--- Context being sent to LLM ---\")\n",
    "    # print(context_string[:1000] + \"...\" if len(context_string) > 1000 else context_string)\n",
    "    # print(\"--- End of Context ---\")\n",
    "\n",
    "    # 4. Get response from LLM\n",
    "    print(\"Getting response from LLM...\")\n",
    "    try:\n",
    "        llm_answer = get_llm_response(user_query, context_string)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM call: {e}\")\n",
    "        return \"An error occurred while trying to generate an answer with the LLM.\"\n",
    "        \n",
    "    # 5. Return the answer (and optionally sources)\n",
    "    # You can enhance this to return structured output\n",
    "    print(\"\\n--- RAG Process Complete ---\")\n",
    "    return llm_answer, sources_metadata\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not LIBRARIES_AVAILABLE or not query_model or not client or not llm_client:\n",
    "        print(\"Exiting: One or more essential components (libraries, models, clients) failed to initialize.\")\n",
    "    else:\n",
    "        # Test queries\n",
    "        queries = [\n",
    "            \"What were Agilent's main business segments in 2018?\",\n",
    "            \"What did Agilent say about the COVID-19 impact in early 2020?\",\n",
    "            \"Summarize the key risks for a major tech company in their 2023 10-K.\",\n",
    "            \"What was Apple's revenue in their latest reported quarter for which data exists?\" # This requires up-to-date data\n",
    "        ]\n",
    "\n",
    "        for q in queries:\n",
    "            answer, sources = answer_query_with_rag(q, top_k_retrieval=3) # Get 3 chunks for context\n",
    "            print(f\"\\n\\nQuery: {q}\")\n",
    "            print(f\"LLM Answer:\\n{answer}\")\n",
    "            \n",
    "            # print(\"\\nSources Used (Payloads):\")\n",
    "            # for i, src_meta in enumerate(sources):\n",
    "            #     print(f\"  Source {i+1} Ticker: {src_meta.get('ticker')}, File: {src_meta.get('original_file_name')}, Section: {src_meta.get('section_name', src_meta.get('turn_section'))}\")\n",
    "            print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
